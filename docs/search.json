[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA-M27 Probability and Statistics for Data Science",
    "section": "",
    "text": "Introduction\nThis module serves as an introduction to the concepts of Probability and Statistics required for Data Science. Both the theoretical concepts and practical examples will be explored throughout the module.\nUse the left panel to navigate the website.\nUse search field on the left to find all instances of a term in the Lecture Notes.\nYou can also use PDF version of these Lecture Notes.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "Ch-01.html",
    "href": "Ch-01.html",
    "title": "1  Basic Concepts in Statistics",
    "section": "",
    "text": "\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nThis section will follow closely Chapter 3 of Essential Math for Data Science by T.Nield (see the Reading List on Canvas).\nIn simple terms, statistics is the collection, analysis and interpretation of data. Data can be qualitative (e.g. hair colour, make of car, etc.) or quantitative (numerical). Data can also be discrete or continuous, where discrete data is distinct, e.g. hair colour and continuous data takes a range of values, e.g. height.\nProbability often plays a large role in statistics, as we use data to estimate how likely an event is to happen.\nStatistics is the heart of many data-driven innovations. Machine learning in itself is a statistical tool, searching for possible hypotheses to correlate relationships between different variables in data.\nWe can easily get caught up in what the data says that we forget to ask where the data comes from. These concerns become all the more important as big data, data mining, and machine learning all accelerate the automation of statistical algorithms. Therefore, it is important to have a solid foundation in statistics and hypothesis testing so you do not treat these automations as black boxes.\n\n\n\n\n\n\nImportantDefinition 1.1\n\n\n\nDescriptive statistics involves using tools, for example calculating the mean, median, mode, and using charts, to describe data.\n\n\nNote that we will recap/cover these concepts shortly.\n\n\n\n\n\n\nImportantDefinition 1.2\n\n\n\nStatistical inference tries to uncover attributes about a larger population, often based on a sample.\n\n\nDescriptive statistics is the most commonly understood part of statistics and we use it to summarise data. Inferential statistics tries to uncover attributes about a larger population, often based on a sample. It is often misunderstood and less intuitive than descriptive statistics. Often we are interested in studying a group that is too large to observe, for example the average height of adults in the UK, and we have to resort to using only a few members of that group to infer conclusions about them. As you can guess, this is not easy to get right. After all, we are trying to represent a population with a sample that may not be representative.\nWe next consider populations, samples and bias.\n\n\n\n\n\n\nImportantDefinition 1.3\n\n\n\nA population is the collection of objects or people under discussion, which can be both finite and infinite.\n\n\nExamples of populations could be “all Swansea University students”, “all adults in the UK”, or “all Golden Retrievers in Scotland”.\nIf we are going to infer attributes about a population based on a sample, it’s important the sample be as random as possible so we do not skew our conclusions, i.e. we want to avoid bias.\n\n\n\n\n\n\nImportantDefinition 1.4\n\n\n\nA sample is any subset of a population.\n\n\nIn practice it is not often possible/practical to gain information about a whole population therefore we often use a sample of the population instead. We work with samples because we want to make inferences about the population, but clearly there is a risk in coming to a false conclusion by making an inference about the whole population using a sample. Therefore there is a need for statistics tests to ensure that similar results would be obtained if a study were to be repeated and that the results are not just due to sampling variability.\n\n\n\n\n\n\nTipRemark 1.5\n\n\n\nIt is important to note that populations can be theoretical and not physically tangible. In these cases our population acts more like a sample from something abstract. For example, let us say that we are interested in flights that depart between 2p.m. and 3p.m. at an airport, but we lack enough flights at that time to reliably predict how often these flights are late. Therefore, we may treat this population as a sample instead from an underlying population of all theoretical flights taking off between 2p.m. and 3p.m.\nProblems like this are why many researchers resort to simulations to generate data. Simulations can be useful but rarely are accurate, as simulations capture only so many variables and have assumptions built in.\n\n\nIntuitively, we know that bias is when something is not evaluated in an objective way, however in statistics we have certain types of bias, see below.\n\n\n\n\n\n\nImportantDefinition 1.6\n\n\n\nA. Confirmation bias is gathering only data that supports your belief, which can even be done unknowingly. An example of this is following only social media accounts you politically agree with, reinforcing your beliefs rather than challenging them.\nB. Self-selection bias is when certain types of subjects are more likely to include themselves in the experiment. For example, this could be walking onto a flight and polling the customers if they like the airline over other airlines, and using that to rank customer satisfaction among all airlines.\nC. Survival bias captures only living and survived subjects, while the deceased ones are never accounted for. For example, many management consulting companies and book publishers like to identify traits of successful companies/individuals and use them as predictors for future successes. These works are pure survival bias, since these works do not account for companies/individuals that failed in obscurity, and these “success” qualities may be commonplace with failed ones as well.\n\n\nWe now look at some descriptive statistics in more detail, beginning with measures of location.\n\n\n\n\n\n\nImportantDefinition 1.7\n\n\n\nThe sample mean, denoted by \\(\\bar{x}\\), of a sample of observations \\(x_1, x_2, \\ldots, x_n\\) is given by \\[\n\\bar{x}=\\frac{1}{n} \\sum_{i=1}^n x_i=\\frac{x_1+x_2+\\cdots+x_n}{n}.\n\\]\nAnalogously, the population mean, denoted by \\(\\mu\\), of a population of observations \\(x_1, \\ldots, x_N\\) is given by \\[\n\\mu=\\frac{1}{N} \\sum_{i=1}^N x_i=\\frac{x_1+x_2+\\cdots+x_N}{N}.\n\\]\n\n\n\nExample 1.8 Eight people from the general UK population were polled on the number of pets they own. The results are shown below: \\[\n1, 3, 2, 5, 7, 0, 2, 3.\n\\] These are the \\(x_1, \\ldots, x_8\\) terms as in the previous definition of the sample mean.Therefore, the sample mean is then given by: \\[\n\\bar{x}=\\frac{1+3+2+5+7+0+2+3}{8}=\\frac{23}{8}=2.875.\n\\]\n\n\nExample 1.9 We now modify the situation of the previous example to where the population is now students studying a certain Mathematics module at Swansea University. The values for the whole population are as follows: \\[\n2,1,3,4,2,6,4,0,1,1,3,3,4,1,1,5,5,2,1,3.\n\\]\nThe population mean is then given by: \\[\n\\begin{aligned}\n\\mu&=\\frac{2+1+3+4+2+6+4+0+1+1+3+3+4+1+1+5+5+2+1+3}{20}\\\\\n&=\\frac{52}{20}=2.6.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nImportantDefinition 1.10\n\n\n\nWe define the weighted mean by \\[\n\\frac{x_1\\cdot w_1+x_2\\cdot w_2+\\cdots+x_n\\cdot w_n}{w_1+w_2+\\cdots+w_n},\n\\] where \\(x_1,\\ldots,x_n\\) denote the observations and \\(w_1,\\ldots,w_n\\) are the corresponding weights.\n\n\n\nExample 1.11 Let us consider a module with three coursework components worth 20% each and a final exam that is worth 40%. A student scores \\(90, 80, 63\\) and 87 respectively in these components. The weights are therefore 0.2, 0.2, 0.2 and 0.4 respectively and the weighted average is given by, \\[\n\\frac{0.2\\cdot90+0.2\\cdot80+0.2\\cdot63+0.4\\cdot87}{0.2+0.2+0.2+0.4}=81.4.\n\\]\n\n\n\n\n\n\n\nImportantDefinition 1.12\n\n\n\nThe median is the middle value of ranked data if \\(n\\) is odd and it is the mean of the two middle values if \\(n\\) is even, i.e.  \\[\n\\frac{\\frac12n^{\\text{th}}+(\\frac12n+1)^{\\text{th}}}{2}.\n\\]\n\n\n\nExample 1.13 Calculate the median of the values: 5,0,1,9,7,10,14. Firstly we rank these values to obtain: \\[\n0,1,5,7,9,10,14.\n\\] Since \\(n\\) is odd (i.e. 7) we take the middle value of 7 to be the median. If we now add one value of 20 to this example, then the modified ranked data is given by: \\[\n0,1,5,7,9,10,14,20.\n\\] Now we have an even number of values (i.e. 8) and hence the median is given by \\(\\tfrac{7+9}{2}=8\\).\n\n\n\n\n\n\n\nTipRemark 1.14\n\n\n\nThere is a concept of quantiles in descriptive statistics. The concept of quantiles is essentially the same as a median, just cutting the data in other places besides the middle. The median is actually the 50% quantile, or the value where 50% of ordered values are behind it. Then there are the 25%, 50%, and 75% quantiles, which are known as quartiles because they cut data in 25% increments.\n\n\n\n\n\n\n\n\nImportantDefinition 1.15\n\n\n\nThe mode is the most frequently occurring set of values. It primarily becomes useful when your data is repetitive and you want to find which values occur the most frequently.\n\n\n\nExample 1.16 Find the mode of the values \\(20,21,19,20,22,19,20\\). The most common value is 20, hence 20 is the mode of this dataset.\n\nThe mode is not necessarily unique, see the example below for an illustration.\n\nExample 1.17 If we return to Example 1.8, we find that the mode for the number of pets is 2 and 3.\n\nWe now consider measures of variation of data. This gives us a sense of how “spread out” the data is. It is important to note that there are some calculation differences for the sample versus the population.\n\n\n\n\n\n\nImportantDefinition 1.18\n\n\n\nA. For a population of data values \\(x_1,\\ldots,x_N\\), the (population) variance is given by, \\[\n\\sigma^2=\\frac{\\sum_{i=1}^N(x_i-\\mu)^2}{N},\n\\] where \\(\\mu\\) is the mean of the population. Furthermore, the (population) standard deviation is the square root of the variance, i.e. \\[\n\\sigma=\\sqrt{\\frac{\\sum_{i=1}^N(x_i-\\mu)^2}{N}.}\n\\]\nB. For a sample of data values \\(x_1,\\ldots,x_n\\), the sample variance is given by, \\[\ns^2=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1},\n\\] where \\(\\bar{x}\\) is the sample mean. Similarly, the sample standard deviation is the square root of the sample variance, i.e. \\[\ns=\\sqrt{\\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}.}\n\\]\n\n\n\n\n\n\n\n\nTipRemark 1.19\n\n\n\nNote that for the sample variance (and hence the sample standard deviation) we divide by \\(n-1\\) rather than the total number of items. We do this to decrease any bias in a sample and not underestimate the variance of the population based on our sample. By counting values short of one item in our divisor, we increase the variance and therefore capture greater uncertainty in our sample.\n\n\n\nExample 1.20 In this example we are interested in studying the number of pets owned by members of staff in a certain shop (note that this is our population, not a sample). The data are as follows: \\[\n0,14,5,9,7,10,1.\n\\] The mean of this sample is 6.571, hence the variance is given by\n\\[\n\\begin{aligned}\n\\sigma^2&=\\frac{\\sum_{i=1}^N(x_i-\\mu)^2}{N}\\\\\n&=\\text{\\scriptsize{$\\dfrac{(0-6.571)^2+(14-6.571)^2+(5-6.571)^2+(9-6.571)^2+(7-6.571)^2+(10-6.571)^2+(1-6.571)^2}{7}$}}\\\\\n&=21.29.\n\\end{aligned}\n\\]\nTherefore the standard deviation is given by \\(\\sigma=\\sqrt{21.38}=4.62\\). (All to 2dp.)\n\n\nExample 1.21 We now modify the previous example to the situation where the data provided are a sample of a larger population. We now calculate the sample variance and standard deviation: \\[\n\\begin{aligned}\ns^2&=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})^2}{n-1}\\\\\n&=\\text{\\scriptsize{$\\dfrac{(0-6.571)^2+(14-6.571)^2+(5-6.571)^2+(9-6.571)^2+(7-6.571)^2+(10-6.571)^2+(1-6.571)^2}{6}$}}\\\\\n&=24.95.\n\\end{aligned}\n\\]\nTherefore the sample standard deviation is given by \\(\\sigma=\\sqrt{24.95}=4.99\\). (All to 2dp.)\n\nNotice that the sample variance and standard deviation have increased compared to the population case. This is correct as a sample could be biased and imperfect representing the population. Therefore, we increase the variance (and thus the standard deviation) to increase our estimate of how spread out the values are. A larger variance/standard deviation shows less confidence with a larger range.\n\n\n\n\n\n\nImportantDefinition 1.22\n\n\n\nMeasures of characteristics of a sample are called statistics. (Not to be confused with the subject area of statistics described above.) The corresponding characteristics in the population are called parameters.\n\n\nWe work with samples because we want to make inferences about the population, but clearly there is a risk in coming to a false conclusion by making an inference about the whole population using a sample. Therefore there is a need for statistics tests to ensure that similar results would be obtained if a study were to be repeated and that the results are not just due to sampling variability.\nThe final topic of this chapter discusses some basic data visualisation techniques - in particular, we will consider histograms, box plots and scatter plots.\n\n\n\n\n\n\nImportantDefinition 1.23\n\n\n\nA histogram is a graphical display of continuous data using bars. A bar chart provides a graphical display of categorical data.\n\n\nNote that there are no gaps between the bars of histograms and the bars can be of varying widths, i.e. they may have different sized intervals or `bins’. Histograms can be used to help determine the distribution of the data.\n\nExample 1.24 In this example we consider the weight of Golden Retrievers. See below for examples of histograms for this data.\nThis histogram does not reveal any meaningful shape to our data. The reason is because our bins are too small.\n\n\n\n\n\n\n\n\n\nFigure 1.1\n\n\n\n\n\nAs you can see, if we get the bin sizes just right (in this case, each has a range of three pounds), we start to get a meaningful bell shape to our data.\n\n\n\n\n\n\nImportantDefinition 1.25\n\n\n\nA box plot or a box-and-whisker plot is a graphical technique to display data using quartiles. The box itself indicates the interquartile range, i.e. the 25% quartile to the 75% quartile. The median is indicated by a line within the box. The end of the lower (or left) whisker indicates the minimum and the top of the upper (or right) whisker denotes the maximum. Outliers are usually indicated by points.\n\n\nBox plots are useful to visualise the distribution of data, in particular to check for symmetry.\n\nExample 1.26 Let us use the data in Example 1.13 to produce the following box plot.\n\n\n\n\n\n\n\n\n\nFigure 1.2\n\n\n\n\n\n\n\n\n\n\n\nImportantDefinition 1.27\n\n\n\nWe obtain bivariate data when we measure two variables on each member of the population or sample.\n\n\nScatter plots can be used to plot such data, these plots can also help to visualise a relationship between the variables. One variable is plotted on the horizontal axis and the other on the vertical axis.\n\nExample 1.28 Let us consider the data below which records exam marks for students and the corresponding time (in hours) the students spent revising for the exam.\nThis can be represented by the following scatter plot:\n\n\n\n\n\n\n\n\n\nFigure 1.3",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basic Concepts in Statistics</span>"
    ]
  },
  {
    "objectID": "Ch-02.html",
    "href": "Ch-02.html",
    "title": "2  Basic Concepts and Rules of Probability",
    "section": "",
    "text": "2.1 Introduction to Probability Theory\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nProbability Theory is a branch of mathematics that deals with uncertainty and randomness. It provides a framework for quantifying and analyzing uncertainty in stochastic experiments.\nProbability theory plays a crucial role in data science, where we often deal with uncertain data and make predictions based on probabilities.\nAn experiment or trial is any procedure that can be infinitely repeated and has a well-defined set of possible outcomes.\nAn outcome (denoted by \\(\\omega\\)) is a particular result of an experiment.\nA sample space (denoted by \\(\\Omega\\)) is the set of all possible outcomes of an experiment (i.e. \\(\\omega\\in\\Omega\\)).\nAn event is a subset of the sample space (e.g. \\(A\\subset \\Omega\\)), representing a specific outcome or a collection of outcomes.\nProbability (denoted by \\(\\P\\)) is a measure of the likelihood of an event occurring. It assigns a number between \\(0\\) and \\(1\\) to an event, where \\(0\\) indicates extreme unlikelihood, and \\(1\\) indicates certainty that the event will occur. In particular, \\[0\\leq \\P(A)\\leq \\P(\\Omega) = 1.\\]\nFigure 2.1: Visual representation of \\(\\P(A)=\\dfrac{\\color{myYellow}\\mathbf{oval}}{\\color{myBlue}\\mathbf{rectangle}}\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Concepts and Rules of Probability</span>"
    ]
  },
  {
    "objectID": "Ch-02.html#introduction-to-probability-theory",
    "href": "Ch-02.html#introduction-to-probability-theory",
    "title": "2  Basic Concepts and Rules of Probability",
    "section": "",
    "text": "Example 2.1 When we throw a coin ones, the possible outcomes are \\(H, T\\) (stand for ‘head’ and ‘tail’).\nTherefore, \\(\\Omega=\\{H, T\\}\\).\nThere are \\(4\\) events one can consider: \\(\\{H\\}, \\{T\\}, \\{H,T\\}, \\emptyset\\).\n\n\nExample 2.2 Consider rolling a fair six-sided dice.\nThe possible outcomes then are \\(1,2,3,4,5,6\\).\nTherefore, \\(\\Omega=\\{1,2,3,4,5,6\\}\\).\nConsider the event \\(A\\) of getting an even number: \\(A = \\{2, 4, 6\\}\\).\nConsider the event \\(B\\) of getting a prime number: \\(B = \\{2, 3, 5\\}\\).\nThen \\(\\P(A)=\\P(B)=\\frac12\\) (think why).\n\n\n\n\n\n\n\nTipRemember\n\n\n\nThe event \\(\\emptyset\\) (‘empty set’) describes an impossible event (e.g. we throw a coin or a dice with no outcome). Then \\[\n\\P(\\emptyset) = 0.\n\\]\n\n\n\nRemark. In the experiment from Example 2.2, the following \\(2^6=64\\) events can be considered \\[\n\\begin{gathered}\n\\emptyset, \\{1\\}, \\{2\\}, \\ldots, \\{6\\},\\\\\n\\{1,2\\}, \\{1,3\\}, \\ldots, \\{5,6\\},\\\\\n\\{1,2,3\\}, \\ldots,  \\{4,5,6\\},\\\\\n\\ldots\\\\\n\\{1,2,\\ldots,6\\}.\n\\end{gathered}\n\\]\n\n\n\n\n\n\n\nTipRemember\n\n\n\nIf the sample space \\(\\Omega\\) contains \\(n\\) elements (outcomes), then the set of all events (that is the set of all subsets of \\(\\Omega\\)) is denoted by \\(2^\\Omega\\), and it contains \\(2^n\\) events.\n\n\n\n\n\n\n\n\nCautionMemorize\n\n\n\nWe start our course with the discrete case, when \\(\\Omega\\) is a finite set. To calculate the probability \\(\\P(A)\\) of an event \\(A\\subset\\Omega\\), we use the following formula: \\[\n\\P(A)=\\dfrac{\\textrm{number of outcomes that make } A}{\\textrm{number of all outcomes}}=\\dfrac{\\sharp(A)}{\\sharp(\\Omega)}\n\\]\n\n\n\n\nExample 2.3 Consider rolling twice a fair six-sided dice. Then outcomes are \\(\\omega=(a,b)\\) where \\(a,b\\in \\{1, 2, 3, 4, 5, 6\\}\\), i.e. \\[\n\\Omega = \\bigl\\{  (a,b) \\mid a,b\\in \\{1, 2, 3, 4, 5, 6\\} \\bigr\\}.\n\\] Then \\(\\sharp(\\Omega)=6\\cdot 6=36\\). Let \\(A\\) be the event of having the sum of the numbers in two rollings bigger than \\(10\\). Then \\[\nA=\\bigl\\{  (5,6), (6,5), (6,6) \\bigr\\}.\n\\] Therefore, \\[\n\\P(A)=\\frac{3}{36}=\\frac1{12}.\n\\]\n\n\nExample 2.4 Consider drawing a card from a standard deck of \\(52\\) playing cards. The sample space \\(\\Omega\\) is the set of all \\(52\\) pairs of the form \\(vS\\), where \\(v\\in\\{A, 2, 3, 4, \\ldots, 10, J, Q, K\\}\\) is the value of a card (here \\(J\\) represents a Jack, \\(Q\\) represents a Queen, \\(K\\) represents a King, and \\(A\\) represents an Ace), and \\(S\\in\\{\\clubsuit,{\\color{red}\\diamondsuit}, \\spadesuit, {\\color{red}\\heartsuit}\\}\\) is the card suit (e.g. \\(2{\\color{red}\\diamondsuit},\\ldots, A{\\color{red}\\diamondsuit}\\) are all diamonds). Let \\(B\\) be the event of drawing a red face card. Then \\[\nB=\\{J{\\color{red}\\diamondsuit}, Q{\\color{red}\\diamondsuit}, K{\\color{red}\\diamondsuit}, J{\\color{red}\\heartsuit}, Q{\\color{red}\\heartsuit}, K{\\color{red}\\heartsuit}\\},\n\\] and hence, \\[\n\\P(B)=\\frac{6}{52}=\\frac{3}{26}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Concepts and Rules of Probability</span>"
    ]
  },
  {
    "objectID": "Ch-02.html#rules-of-probability",
    "href": "Ch-02.html#rules-of-probability",
    "title": "2  Basic Concepts and Rules of Probability",
    "section": "2.2 Rules of Probability",
    "text": "2.2 Rules of Probability\n\nDefinition 2.5 The sum of events \\(A\\) and \\(B\\) is the event \\(A+B\\) (also denoted \\(A\\cup B\\) or \\(A\\vee B\\)) which occurs iff either \\(A\\) occurs or \\(B\\) occurs or they both occur.\n\n\n\n\n\n\n\n\n\nFigure 2.2: Visual representation of \\(A+ B\\)\n\n\n\n\n\n\nDefinition 2.6 The product of events \\(A\\) and \\(B\\) is the event \\(AB\\) (also denoted \\(A\\cap B\\) or \\(A\\wedge B\\)) which occurs iff both \\(A\\) and \\(B\\) occur.\n\n\n\n\n\n\n\n\n\nFigure 2.3: Visual representation of \\(AB\\)\n\n\n\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\n\n\\(A+B\\) occurs under more outcomes than either of \\(A\\) or \\(B\\) alone: \\[\n\\P(A+B) \\geq \\P(A), \\quad\n\\P(A+B) \\geq \\P(B).\n\\]\n\\(AB\\) occurs under less outcomes than each of \\(A\\) or \\(B\\) alone: \\[\n\\P(AB) \\leq \\P(A), \\quad\n\\P(AB) \\leq \\P(B).\n\\]\n\n\n\n\n\n\n\n\n\nCautionMemorize\n\n\n\nThe addition rule states that \\[\n\\P(A + B) = \\P(A) + \\P(B) - \\P(A B).\n\\] It can be easily interpretted using the visual representations of \\(\\P(A + B)\\) and \\(\\P(AB)\\).\n\n\n\nExample 2.7 There is a standard deck of \\(52\\) playing cards. Find the probability of drawing either a red card or a face card (king, queen, or jack) from the deck in a single draw.\nSolution: Let \\(A\\) be the event of drawing a red card, and \\(B\\) be the event of drawing a face card. Overall, there are \\(26\\) red cards, \\(12\\) face cards, and \\(6\\) red face cards. Therefore, \\[\n\\P(A+B)=\\frac{26}{52}+\\frac{12}{52}-\\frac{6}{52}=\\frac{32}{52}=\\frac{8}{13}.\n\\]\n\n\n\n\n\n\n\nTipRemember\n\n\n\nEvents \\(A\\) and \\(B\\) are called mutually exclusive events if only one of them may happen, i.e. if \\(AB=\\emptyset\\). In this case \\(\\P(AB)=0\\), and the addition rule takes the form \\[\n\\P(A+B)=\\P(A)+\\P(B).\n\\]\n\n\n\nDefinition 2.8 The complement to an event \\(A\\) is the event \\(A^c\\) which occurs iff \\(A\\) does not occur. Since \\(\\P(\\Omega)=1\\), one has \\[\n\\P(A^c)=1-\\P(A).\n\\]\n\n\n\n\n\n\n\n\n\nFigure 2.4: Visual representation of \\(A^c\\)\n\n\n\n\n\n\nExample 2.9 A fair six-sided dice is rolling three times. Find the probability that the total score (the sum of three trials) will be at least \\(4\\) (event \\(A\\)).\nSolution: The sample space \\(\\Omega\\) consists of all triples \\((a,b,c)\\) with \\(a,b,c\\in\\{1,2,\\ldots,6\\}\\). Thus, \\(\\sharp(\\Omega)=6^3=216\\). The total score is \\(4\\) or more in all cases but the case \\((1,1,1)\\). Therefore, the answer is: \\[\n\\P(A) = 1-\\P(A^c)=1-\\frac{1}{216}=\\frac{215}{216}.\n\\]\n\n\nDefinition 2.10 Conditional probability \\(\\P(A\\mid B)\\) is the probability of an event \\(A\\) occurring given that event \\(B\\) has already occurred, so we assume that \\(\\color{red}\\P(B)\\neq0\\). The formula is \\[\n\\P(A\\mid B) = \\frac{\\P(AB)}{\\P(B)}.\n\\]\n\n\n\n\n\n\n\nCautionMemorize\n\n\n\nThe multiplication rule follows immediately from the formula for the conditional probability: \\[\n\\P(AB) =  \\P(B)\\, \\P(A\\mid B) = \\P(A)\\, \\P(B\\mid A).\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nThe multiplication rule can be generalised for the product of several events, e.g. \\[\n\\P(ABC) = \\P(A) \\, \\P(B\\mid A)\\,\\P(C\\mid AB).\n\\]\n\n\n\nExample 2.11 In a bag of \\(20\\) marbles, \\(8\\) are red, and \\(12\\) are green. Three marbles are drawn from the bag without replacement. What is the probability that they all are of the same color?\nSolution: we need to find the probability that either \\(A=(r,r,r)\\) or \\(B=(g,g,g)\\) holds. Note that \\(A\\) and \\(B\\) are mutually exclusive events. By the multiplication rule, \\[\n\\P(A) = \\frac{8}{20}\\cdot\\frac{7}{19}\\cdot\\frac{6}{18},\n\\] and \\[\n\\P(B) = \\frac{12}{20}\\cdot\\frac{11}{19}\\cdot\\frac{10}{18}.\n\\]\nTherefore, by the addition rule (for mutually exclusive events), \\[\n\\P(A+B)=\\P(A)+\\P(B)=\\frac{8\\cdot 7\\cdot 6}{20\\cdot 19\\cdot 18}+\\frac{12\\cdot 11\\cdot 10}{20\\cdot 19\\cdot 18}=\\frac{1656}{6840}=\\frac{23}{95}.\n\\]\n\n\nDefinition 2.12 An event \\(A\\) is said to be independent on an event \\(B\\) if the occurrence of \\(B\\) does not affect the probability of occurrence of \\(A\\). In other words, \\(A\\) is independent on \\(B\\) iff \\[\n\\P(A\\mid B) = \\P(A).\n\\]\n\n\nExample 2.13 A fair coin is tossing twice. Let \\(A\\): a head appeared in the first tossing, and \\(B\\): a tail appeared in the second tossing. Then \\(A\\) and \\(B\\) are independent. \\(A=\\{HH,HT\\}\\), \\(B=\\{HT,TT\\}\\), and hence, \\(AB=\\{HT\\}\\). Then \\(\\P(AB)=\\frac14=\\frac12\\cdot\\frac12=\\P(A)\\P(B)\\).\n\n\n\n\n\n\n\nTipRemember\n\n\n\nIf \\(A\\) is independent on \\(B\\) then \\(B\\) is independent on \\(A\\), and \\[\n\\P(AB)=\\P(A)\\,\\P(B).\n\\]\n\n\n\nRemark. If three (or more) events are pairwise independent: \\(A\\) and \\(B\\) are independent, the same for \\(B\\) and \\(C\\), and for \\(A\\) and \\(C\\), it still may be that they are not independent in total, and then, in general, \\(\\P(ABC)\\neq\\P(A)\\P(B)\\P(C)\\) (see the multiplication rule).\n\n\n\n\n\n\n\n\n\nFigure 2.5: Note that \\(A=AB_1+\\ldots +AB_n\\)\n\n\n\n\n\n\n\n\n\n\n\nCautionMemorize\n\n\n\nLet \\(B_1,\\ldots,B_n\\) be pairwise exclusive events (i.e. \\(B_iB_j=\\emptyset\\) for all \\(i\\neq j\\)) such that \\(B_1+B_2+\\ldots+B_n=\\Omega\\) with \\(\\P(B_i)\\neq0\\) (it is said then that \\(B_1,\\ldots,B_n\\) form a partition of \\(\\Omega\\)). Then the law of total probability holds: \\[\n\\P(A)=\\P(A\\mid B_1)\\,\\P(B_1)+\\ldots+\\P(A\\mid B_n)\\,\\P(B_n).\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nThere is also a modification of the law of total probability for conditional probabilioties. If \\(B_1,\\ldots,B_n\\) are as above and \\(\\P(C)\\neq0\\), then \\[\n\\P(A\\mid C) = \\P(A\\mid B_1 C)\\P(B_1\\mid C)+\n\\ldots + \\P(A\\mid B_n C)\\P(B_n\\mid C).\n\\]\n\n\nFrom Definition 2.10, we have that \\[\n\\P(B) \\P(A\\mid B) = \\P(AB)=\\P(BA)=\\P(A)\\P(B\\mid A).\n\\] This implies the following important statement.\n\n\n\n\n\n\nImportantMemorize\n\n\n\nLet \\(\\P(A)\\neq0\\) and \\(\\P(B)\\neq0\\). Then Bayes’ rule (a.k.a. Bayes’ formula or Bayes’ theorem) holds: \\[\n\\P(A\\mid B) = \\frac{\\P(A)\\P(B\\mid A)}{\\P(B)}.\n\\] It describe the a posteriori probability of the event \\(A\\), after an experiment with the known outcome \\(B\\), using the a priori information about the outcome \\(B\\).\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nIf \\(A_1,\\ldots,A_n\\) form a partition of \\(\\Omega\\) (i.e. \\(A_1+\\ldots+A_n=\\Omega\\) and \\(A_iA_j=\\emptyset\\) for \\(i\\neq j\\)) with \\(\\P(A_j)\\neq0\\), then we can rewrite Bayes’ rule as follows, for \\(\\P(B)\\neq0\\): \\[\n\\P(A_i\\mid B) = \\dfrac{\\P(A_i)\\P(B\\mid A_i)}{\\displaystyle\\sum_{j=1}^n\\P(B\\mid A_j)\\P(A_j)}.\n\\]\n\n\n\nExample 2.14 A patient has taken a test for a rare disease. The prevalence of the disease in the population is known to be very low, only \\(0.1\\)%. The test correctly identifies the disease in \\(95\\)% of cases when it’s present. The test incorrectly indicates the presence of the disease in \\(3\\)%, of cases where it’s not actually present. The patient has just received a positive test result for the disease. What is the probability that he actually has the disease?\nSolution: Let \\(D\\) denote the event of having the desease for a member of the population, then \\(\\P(D) = 0.001\\) (\\(0.1\\)%). Let \\(T\\) denote the event of the positive test result. Then we know that \\[\n\\P(T|D) = 0.95, \\qquad \\P(T|D^c) = 0.03.\n\\] By the very definition, \\(D\\) and \\(D^c\\) form a partition of \\(\\Omega\\). Then \\[\n\\P(D|T) = \\frac{\\P(T|D) \\cdot \\P(D)}{\\P(T|D) \\cdot \\P(D) + \\P(T|D^c) \\cdot \\P(D^c)} = \\frac{0.95 \\cdot 0.001}{0.95 \\cdot 0.001 + 0.03 \\cdot (1 - 0.001)} \\approx 0.0306.\n\\] So, given a positive test result for the disease, the probability that the patient actually has the disease is just \\(3.06\\)%.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Concepts and Rules of Probability</span>"
    ]
  },
  {
    "objectID": "Ch-03.html",
    "href": "Ch-03.html",
    "title": "3  Discrete Probability Distributions",
    "section": "",
    "text": "3.1 Discrete Random Variables and their Characteristics\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nFigure 3.1: Cumulative function of the random variable \\(X:\\Omega\\to\\{0,2,3\\}\\) with \\(\\P(X=0)=0.2\\), \\(\\P(X=2)=\\P(X=3)=0.4\\)\nProbability distributions provide a way to model and analyze random phenomena.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-03.html#discrete-random-variables-and-their-characteristics",
    "href": "Ch-03.html#discrete-random-variables-and-their-characteristics",
    "title": "3  Discrete Probability Distributions",
    "section": "",
    "text": "Definition 3.1 A random variable is a quantity which depends on random events. More rigorously, a random variable \\(X\\) is a function \\(X:\\Omega\\to\\mathbb{R}\\).\n\n\nExample 3.2 Three fair six-sided dices are thrown simultaneously. Let \\(X\\) be the sum of scores on the dices. Then \\(\\Omega\\) consists of \\(\\omega=(a,b,c)\\) where \\(a,b,c\\in\\{1,\\ldots,6\\}\\), and \\(X:\\Omega\\to\\mathbb{R}\\), \\(X(\\omega)=a+b+c\\). Thus, \\(X\\) may take only values from the finite set \\(\\{3,4,\\ldots,18\\}\\), and hence, \\(X\\) is a discrete random variable.\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nIf a random variable \\(X\\) takes values only from a discrete set \\(\\{x_1,x_2,\\ldots\\}\\), then \\(X\\) is called a discrete random variable. If \\(X\\) can take any values from an interval on the real line, then \\(X\\) is called a continuous random variable.\n\n\n\nDefinition 3.3 A probability distribution of a random variable \\(X:\\Omega\\to\\mathbb{R}\\) is a mapping which assigns to each interval \\(E\\subset\\mathbb{R}\\) the value of \\(\\P\\bigl(X\\in E\\bigr)\\).\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe cumulative distribution function (CDF) of a discrete random variable \\(X:\\Omega\\to\\{x_1,x_2,\\ldots\\}\\) is the function \\(F_X:\\mathbb{R}\\to[0,1]\\) defined by \\[\nF_X(x) = \\sum_{x_i\\leq x} \\P(X=x_i) \\  {\\color{red}=\\P(X\\leq x)}.\n\\]\n\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nA discrete probability density function (discrete PDF) a.k.a. a probability mass function (PMF) is a function that gives the probability that a discrete random variable is exactly equal to some value: \\[\np_X(x)=\\P(X=x).\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\n\n\\(0\\leq F_X(x)\\leq 1\\)\n\\(F_X\\) is non-decreasing\n\\(\\P(a{\\color{red}&lt;} X {\\color{red}\\leq} b)=F_X(b)-F_X(a)\\)\n\\(0\\leq p_X(x)\\leq 1\\)\nIf \\(X:\\Omega\\to \\{x_1,x_2,\\ldots\\}\\) then \\[\np_X(x_1)+p_X(x_2)+\\ldots = 1\n\\]\n\n\n\n\nExample 3.4 You throw two six-sided fair dice and calculate the sum of the numbers rolled. Let \\(X\\) be the random variable representing the sum. Find and sketch the CDF of \\(X\\).\nSolution: We have that \\(\\Omega=\\bigl\\{(a,b)\\mid a,b\\in\\{1,2,\\ldots,6\\}\\bigr\\}\\), and for \\(\\omega=(a,b)\\), \\(X(\\omega)=a+b\\). Then \\(X\\in\\{2,3,\\ldots,12\\}\\), and \\[\np_X(k) = \\P(X=k)= \\frac{\\sharp\\{(a,b)\\mid a+b=k\\}}{\\sharp(\\Omega)}.\n\\] Note that \\(\\sharp(\\Omega)=6\\cdot6=36\\). Next \\[\n\\begin{gathered}\n2=1+1, \\quad 3=1+2=2+1, \\quad 4=1+3=2+2=3+1, \\\\\n5=1+4=2+3=3+2=4+1,\\quad  \n6=1+5=2+4=3+3=4+2=5+1, \\\\ 7=1+6=2+5=3+4=4+3=5+2=6+1, \\quad 8=2+6=3+5=4+4=5+3,\\\\\n9=3+6=3+5=5+4=6+3, \\quad 10=4+6=5+5=6+4, \\\\ 11=5+6=6+5, \\quad 12=6+6,\n\\end{gathered}\n\\] therefore, \\[\n\\begin{aligned}\np_X(2) = \\frac1{36}, && p_X(3) = \\frac{2}{36}, && p_X(4) = \\frac{3}{36}, &&\np_X(5) = \\frac{4}{36}, \\\\ p_X(6) = \\frac{5}{36}, && p_X(7) = \\frac{6}{36}, &&\np_X(8) = \\frac{5}{36}, && p_X(9) = \\frac{4}{36}, \\\\ p_X(10) = \\frac{3}{36}, &&\np_X(11) = \\frac{2}{36}, && p_X(12) = \\frac{1}{36} . &&\n\\end{aligned}\n\\] Therefore, \\[\nF_X(x)=\\begin{cases} 0, & \\text{if } x&lt;2,\\\\\n\\frac{1}{36}, & \\text{if } 2 \\leq x &lt; 3 \\\\\n\\frac{3}{36}, & \\text{if } 3 \\leq x &lt; 4 \\\\\n\\frac{6}{36}, & \\text{if } 4 \\leq x &lt; 5 \\\\\n\\frac{10}{36}, & \\text{if } 5 \\leq x &lt; 6 \\\\\n\\frac{15}{36}, & \\text{if } 6 \\leq x &lt; 7 \\\\\n\\frac{21}{36}, & \\text{if } 7 \\leq x &lt; 8 \\\\\n\\frac{26}{36}, & \\text{if } 8 \\leq x &lt; 9 \\\\\n\\frac{30}{36}, & \\text{if } 9 \\leq x &lt; 10 \\\\\n\\frac{33}{36}, & \\text{if } 10 \\leq x &lt; 11 \\\\\n\\frac{34}{36}, & \\text{if } 11 \\leq x &lt; 12 \\\\\n1, & \\text{if } x \\geq 12.\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe expected value (mean) \\(\\E(X)\\) of a random variable \\(X\\) is the average value it takes. If \\(X:\\Omega\\to\\{x_1,x_2,\\ldots\\}\\), then \\[\n\\E(X):=\\sum_i x_i\\cdot p_X(x_i)=\n\\sum_i x_i\\cdot \\P(X=x_i).\n\\]\n\n\n\nExample 3.5 Calculate the expected value of the random variable \\(X\\) (sum of two fair six-sided dice rolls) created in Example 3.4.\nSolution: We have \\[\n\\begin{aligned}\n\\E(X)&=\\sum_{i=2}^{12} i\\cdot p_X(i)\\\\\n&= 2\\cdot \\frac1{36}+3\\cdot \\frac{2}{36}+4\\cdot \\frac{3}{36}+5\\cdot\\frac{4}{36} + 6\\cdot\\frac{5}{36}+7\\cdot\\frac{6}{36}\\\\\n&\\quad+8\\cdot\\frac{5}{36}+ 9\\cdot\\frac{4}{36}+10\\cdot\\frac{3}{36}+11\\cdot\\frac{2}{36}+12\\cdot\\frac{1}{36} = \\frac{252}{36}=7.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nTipRemember\n\n\n\n\nFor any random variable \\(X:\\Omega\\to\\R\\) and any number \\(a\\in\\R\\), \\[\n\\E(a X) = a \\E(X).\n\\]\nFor any random variables \\(X,Y:\\Omega\\to\\R\\), \\[\n\\E(X+Y) = \\E(X) + \\E(Y).\n\\]\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe variance \\(\\var(X)\\) of a random variable \\(X\\) is a measure of the spread of its values. \\[\n\\var(X) = \\E\\Bigl((X - \\E(X))^2\\Bigr)=\\E\\bigl(X^2\\bigr) - \\bigl(  \\E(X)\\bigr)^2\\geq0.\n\\]\n\n\n\nExample 3.6 Calculate the variance of the random variable \\(X\\) (sum of two fair six-sided dice rolls) created in Example 3.4.\nSolution: We can use the formula \\[\n\\begin{aligned}\n\\var(X)&=\\sum_{i=2}^{12} i^2\\cdot p_X(i)-\\bigl(  \\E(X)\\bigr)^2\\\\\n&= 2^2\\cdot \\frac1{36}+3^2\\cdot \\frac{2}{36}+4^2\\cdot \\frac{3}{36}+5^2\\cdot\\frac{4}{36} + 6^2\\cdot\\frac{5}{36}+7^2\\cdot\\frac{6}{36}\\\\\n&\\quad+8^2\\cdot\\frac{5}{36}+ 9^2\\cdot\\frac{4}{36}+10^2\\cdot\\frac{3}{36}+11^2\\cdot\\frac{2}{36}+12^2\\cdot\\frac{1}{36} - 7^2\\\\\n&= \\frac{1974}{36}-49=\\frac{35}{6}\\approx 5.83.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe standard deviation of a random variable \\(X:\\Omega\\to\\R\\) is the square root of the variance of \\(X\\): \\[\n\\sigma(X) := \\sqrt{\\var(X)}.\n\\]\n\n\n\nDefinition 3.7 Two random variables \\(X:\\Omega\\to\\R\\) and \\(Y:\\Omega\\to\\R\\) are called independent if, for any \\(a,b\\in\\R\\), the events \\[\n\\{X\\leq a\\}:=\\{\\omega\\in\\Omega\\mid X(\\omega)\\leq a\\}\n\\qquad\\text{and}\\qquad\n\\{Y\\leq b\\}:=\\{\\omega\\in\\Omega\\mid Y(\\omega)&lt;b\\}\n\\] are independent.\n\n\n\n\n\n\n\nTipRemember\n\n\n\n\nFor any random variable \\(X:\\Omega\\to\\R\\) and any number \\(a\\in\\R\\), \\[\n\\var(a X) = a^{\\color{red}2} \\var(X).\n\\]\nFor any \\({\\text{\\color{red}independent}}\\) random variables \\(X,Y:\\Omega\\to\\R\\), \\[\n\\E(XY) = \\E(X) \\cdot \\E(Y)\n\\] and \\[\n\\var(X+Y) = \\var(X) + \\var(Y).\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-03.html#bernoulli-trials",
    "href": "Ch-03.html#bernoulli-trials",
    "title": "3  Discrete Probability Distributions",
    "section": "3.2 Bernoulli Trials",
    "text": "3.2 Bernoulli Trials\n\nDefinition 3.8 Conisder an experiment with two only possible outcomes: success (denoted by \\(1\\)) and failure (denoted by \\(0\\)). We will call such experiments Bernoulli trials.\n\n\n3.2.1 Bernoulli Distribution\n\nDefinition 3.9 A random variable \\(X\\) has the Bernoulli distribution if \\(X\\) can take only two values, usually they are \\(1\\) and \\(0\\). It models, hence, a Bernoulli trial. \\(X\\) is fully characterized by a single parameter \\(p\\in[0,1]\\), the probability of success, i.e. its PMF (probability mass function) is \\[\np_X(1)=\\mathbb{P}(X=1) = p, \\qquad p_X(0)=\\mathbb{P}(X=0) = 1-p.\n\\]\n\n\n\n\n\n\n\nTipRemember\n\n\n\nSince \\(X=X^2\\), we have that \\[\n\\begin{aligned}\n\\E(X)&=\\E(X^2)=1\\cdot p+0\\cdot (1-p)=p,\\\\\n\\var(X)&=p-p^2=p(1-p).\n\\end{aligned}\n\\]\n\n\n\n\n3.2.2 Binomial Distribution\n\nDefinition 3.10 The binomial distribution models the number of successes in a fixed number of independent and identically distributed Bernoulli trials. It is fully characterized by two parameters: \\(n\\) (the number of trials) and \\(p\\) (the probability of success in each trial). We denote this \\(X\\sim Bin(n,p)\\).\nNote that the number \\(k\\) of successes in \\(n\\) trials may be any integer number between \\(0\\) (no successes at all) and \\(n\\) (all trials were successful).\n\n\nRemark. Recall that \\[\nn! =  1\\cdot 2\\cdot \\ldots \\cdot n\n\\] is called the factorial of \\(n\\).\nWe set \\[\n0! = 1,\n\\] and also \\[\n\\binom{n}{0}=\\binom{0}{0}=1.\n\\]\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe PMF of the Binomial distribution is: \\[\np_X(k) = \\P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k},\n\\] where \\(\\binom{n}{k}\\) represents the binomial coefficient, defined as \\[\n\\binom{n}{k} = \\frac{n!}{k!(n-k)!}=\\frac{\\overbrace{n\\cdot(n-1)\\cdot(n-2)\\cdot\\ldots\\cdot(n-k+1)}^{k\\ \\mathrm{factors}}}{1\\cdot2\\cdot3\\cdot\\ldots\\cdot k}.\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nWe can write \\(X=Y_1+\\ldots+Y_n\\) where \\(Y_1,\\ldots,Y_n\\) are independent random variables with identical Bernoulli distributions with the parameter \\(p\\). Then \\[\n\\E(X) = np, \\qquad \\var(X) = np(1-p).\n\\]\n\n\n\nRemark. Recall that the sum of all values of the PMF should be \\(1\\), i.e. \\[\n\\begin{aligned}\n&\\quad \\sum_{k=0}^n \\P(X=k) \\\\\n&= \\sum_{k=0}^n \\binom{n}{k} p^k (1-p)^{n-k} =1.\n\\end{aligned}\n\\] The latter equality is just the binomial formual.\n\n\nExample 3.11 In a game, a player has a \\(20\\)% chance of winning each round. If the player plays \\(5\\) rounds, calculate the probability of winning exactly \\(3\\) rounds.\nSolution: since \\(n = 5\\) (number of rounds) and \\(p = 0.2\\) (probability of winning a round), we can calculate \\[\n\\P(X = 3) = \\binom{5}{3} (0.2)^3 (1-0.2)^{5-3} = \\frac{5\\cdot 4\\cdot 3}{1\\cdot 2\\cdot 3} \\cdot 0.008 \\cdot 0.64 = 0.0512.\n\\]\n\n\nExample 3.12 A company manufactures light bulbs, and \\(90\\)% of them are of good quality, while the rest are defective. If a customer buys \\(50\\) light bulbs, what is the expected number of defective bulbs in the purchase?\n\nRemark. Note that “success” does not need to mean that something good happened, it depends on what we are going to calculate.\n\nSolution: Since we are interested in the number of defective bulbs, we consider a Bernoulli trial where success would mean that a bulb is defective. Then \\(p=0.1\\) and \\(n=50\\), therefore, \\[\n\\E(X)=50 \\cdot 0.1 =5.\n\\] So, the expected number of defective bulbs in the purchase is \\(5\\).\n\n\nRemark. Remember, the following relation may be useful: \\[\n\\color{red}\\binom{n}{k}=\\binom{n}{n-k}.\n\\] For example, \\[\n\\begin{aligned}\n\\binom{50}{49}&=\\binom{50}{1}=50,\\\\\n\\binom{50}{48}&=\\binom{50}{2}=\\frac{50\\cdot49}{2}.\n\\end{aligned}\n\\]\n\n\nExample 3.13 A basketball player has a free throw success rate of \\(70\\)%. If she attempts \\(20\\) free throws, find the variance of the number of successful free throws.\nSolution: In this case, \\(p=0.7\\) is the probability of making a free throw, and \\(n=20\\). Therefore, \\[\n\\var(X)=\\sigma_X^2 = 20 \\cdot 0.7 \\cdot (1-0.7) = 4.2.\n\\] So, the variance of the number of successful free throws is \\(4.2\\).\n\n\n\n3.2.3 Geometric Distribution\n\nDefinition 3.14 The geometric distribution models the number of trials needed to achieve the first success in a sequence of independent and identically distributed Bernoulli trials. It is characterized by a parameter \\(p\\) (the probability of success in each trial). We denote this \\(X\\sim Geom(p)\\).\n\nThe corresponding random variable can take any natural value \\(n=1,2,3,\\ldots\\) (where \\(n\\) denotes the number of the first succesful trial).\n\nRemark. We have that \\[\n\\begin{aligned}\n&\\quad \\sum_{n=1}^\\infty \\P(X=n)\\\\\n&= \\sum_{n=1}^\\infty (1-p)^{n-1} p\\\\\n& = \\frac{p}{1-(1-p)}=1.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nWe assume that \\(p\\neq0\\) (otherwise, we would need infinitely many trials for success). The PMF of the geometric distribution is: \\[\n\\P(X = n) = (1-p)^{n-1} p.\n\\] Also: \\[\n\\E(X) = \\frac1p,\\qquad \\var(X)=\\frac{1-p}{p^2}.\n\\]\n\n\n\nExample 3.15 A student is preparing for a multiple-choice exam, where each question has \\(4\\) choices, and only one is correct. If the student guesses the answers, what is the probability that the first correct answer occurs on the third guess? How many guesses the student would need to do in average to get the correct answer?\nSolution: In this case, \\(p = \\frac{1}{4}\\) (probability of guessing the correct answer) and we want to find \\[\n\\P(X = 3) = (1-\\frac{1}{4})^{3-1} \\cdot \\frac{1}{4} = \\frac{9}{64}.\n\\] Next, \\[\n\\E(X)=\\frac1p=\\dfrac{1}{\\frac14}=4,\n\\] i.e. in average, the student would need to do \\(4\\) guesses to answer correctly.\n\n\n\n3.2.4 Negative Binomial Distribution\n\nDefinition 3.16 The negative binomial distribution models the number of failures in a sequence of independent and identically distributed Bernoulli trials before a specified number of successes occurs. It is characterized by two parameters: \\(r\\) (the number of successes) and \\(p\\) (the probability of success in each trial). We denote this \\(X\\sim NB(r,p)\\).\n\nIf \\(X=k\\) is the considered number of failures, the total required number of trials is \\(n=k+r\\).\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe PMF of the negative binomial distribution is: \\[\n\\P(X = k) = \\binom{k+r-1}{k} p^r (1-p)^{k}.\n\\] Also: \\[\n\\E(X) = \\frac{r(1-p)}{p}=\\frac{r}{p}-r, \\qquad \\var(X) = \\frac{r(1-p)}{p^2}\n\\]\n\n\n\nExample 3.17 A student is practicing basketball free throws with a success probability of \\(0.7\\). The student stops as soon as they achieves \\(3\\) successful free throws. What is the probability that by that time the student would have \\(2\\) failures (unsuccessful throws)?\n\nRemark. The equivalent formulation of Example 3.17 is:\nWhat is the probability that it will take the student exactly \\(5\\) trials to make \\(3\\) successful free throws?\n\nSolution: In this problem, \\(p = 0.7\\) (probability of success), \\(r = 3\\) (number of desired successes), and \\(k = 2\\) (number of failures). Then \\[\n\\P(X = 2) = \\binom{2+3 - 1}{2} \\cdot (0.7)^3 \\cdot (0.3)^{2} = \\frac{4\\cdot 3}{1\\cdot2}\\cdot 0.49\\cdot 0.09=0.2646.\n\\]\n\n\nExample 3.18 In a quality control process, a manufacturer wants to inspect several items to find \\(2\\) defective items. If the probability of finding a defective item is \\(0.1\\), what is the expected number of items that need to be inspected?\nSolution: In this problem, \\(p = 0.1\\), and \\(r = 2\\). The number \\(X\\) of items that need to be inspected to find \\(r=2\\) defective items is the sum of the number \\(Y\\) of proper (non-defective) items and number \\(2\\) of defective items, i.e. \\(X=Y+2\\), where \\(Y\\) has the negative binomial distribution as the number of “failures” (here “success” is to find a defective item). Then \\[\n\\E(Y) = \\frac{2}{0.1}-2 = 18,\n\\] and hence, \\[\n\\E(X)=\\E(Y+2)=\\E(Y)+2=20.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-03.html#poisson-distribution",
    "href": "Ch-03.html#poisson-distribution",
    "title": "3  Discrete Probability Distributions",
    "section": "3.3 Poisson Distribution",
    "text": "3.3 Poisson Distribution\n\nDefinition 3.19 The Poisson distribution models the number of independent events occurring in a fixed interval of time or space. It is characterized by a single parameter \\(\\lambda&gt;0\\) (the average rate of events per interval of the same size). We denote this by \\(X\\sim Po(\\lambda)\\).\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe PMF of the Poisson distribution is: \\[\n\\P(X = n) = \\frac{\\lambda^n}{n!}e^{-\\lambda}.\n\\] The expected value and the variance of the Poisson random variable are equal: \\[\n\\E(X)=\\var(X)=\\lambda.\n\\]\n\n\n\nRemark. Note that \\[\n\\sum_{n=0}^\\infty\\frac{\\lambda^n}{n!}e^{-\\lambda}=1.\n\\]\n\n\n\n\n\n\n\nTipRemember\n\n\n\nIt is crucial to use for \\(\\lambda\\) the average rate of events per interval under investigation (see Example 3.20 below).\n\n\n\nExample 3.20 In a call center, calls arrive at an average rate of \\(5\\) calls per minute. Calculate the probability that\n\nexactly \\(15\\) calls will arrive in the next \\(2\\) minutes;\nat least \\(2\\) calls will arrive in the next \\(30\\) seconds.\n\nSolution:\n\nSince we are interested in the number of call within \\(2\\) minutes, one needs to find the average rate of calls per \\(2\\) minutes, that is \\(2\\cdot 5=10\\) calls. Hence, \\(\\lambda=6\\). Then, for \\(X\\sim Po(10)\\), \\[\n\\P(X = 15) = \\frac{10^{15}}{15!}e^{-10}\\approx 0.0347.\n\\]\nWe need to find \\[\n\\P(X\\geq 2)=\\P(X=2)+\\P(X=3)+\\P(X=4)+\\ldots\n\\] (infinitely many). Instead, we can find the probability of compliment event: \\[\n\\P(X\\leq 1)=1-\\P(X\\geq 2).\n\\] To find \\(\\lambda\\) we notice that the time interval is not \\(30\\) seconds, i.e. \\(0.5\\) minutes, and hence, the average rate of calls per \\(30\\) seconds is \\(0.5\\cdot 5=2.5\\). Hence, \\(\\lambda=2.5\\) and \\[\n\\begin{aligned}\n\\P(X\\leq 1)&=\\P(X=0)+\\P(X=1)\\\\\n&=\\frac{2.5^{0}}{0!}e^{-2.5}\n+\\frac{2.5^{1}}{1!}e^{-2.5}=e^{-2.5}+2.5e^{-2.5}\\\\\n&=3.5e^{-2.5}\\approx 0.2873.\n\\end{aligned}\n\\] Therefore, \\[\n\\P(X\\geq 2)=1-\\P(X\\leq 1)\\approx 1-0.2873=0.7127.\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nOften, in the problems, \\(\\lambda\\) is understood is the average rate per unit time. Then the PMF of the distribution of events accuring in a time interval of length \\(t\\) (meaning “\\(t\\) units of time”) is \\[\n\\P(X = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Discrete Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-04.html",
    "href": "Ch-04.html",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "",
    "text": "4.1 The Method of Least Squares\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nUseful resources for linear regression are Theory and Problems of Probability and Statistics by M.R.Spiegel and How to Use Statistics by S.Lakin. Furthermore, useful resources for logistic regression are Generalised Linear Models by P.McCullagh and J.A.Nelder, and Using Multivariate Statistics by B.G.Tabachnick and L.S.Fidell. The material taught in this chapter will also be met from a machine learning perspective in MA-M17 Modelling and Machine Learning — please see chapters 5 and 6 of Essential Math for Data Science by T.Nield if you would like an insight into this.\nRecall in Example 1.28 we discussed bivariate data and associated scatter plot. Sometimes it is visually clear that a linear relationship exists between the variables, for example, in the scatter plot in Example 1.28 it seems that the more time is spent revising the higher the exam mark the student receives. The diagram above contains the same data, but with a line indicating the likely relationship between the variables.\nA linear regression fits a straight line to observed data, attempting to demonstrate a linear relationship between variables and make predictions on new data yet to be observed. The following method will begin to address this.\nOnce a statistical model has been set up, its parameters must be estimated from the data. The method of least squares can provide good such estimates. The method minimises the sum of squared residuals, i.e. it minimises the sum of the square of the differences between an observed value and the value produced by the model. We will concentrate on linear least squares which will provide the theory behind simple linear regression.\nFigure 4.2\nAssuming that we have data pairs \\((x_1,y_1),\\ldots,(x_n,y_n)\\), the model line will take the form \\[\n\\E(y)=\\beta_0+\\beta_1x,\n\\] where \\(y\\) is the dependent variable (response variable) (it depends on \\(x\\)!) and \\(x\\) is the independent variable (explanatory/predictor variable) (it does not depend on another variable). In fact the variables will be related by \\[\ny=\\beta_0+\\beta_1x+\\epsilon,\n\\] where \\(\\epsilon\\) is the error. It is clear that there is some error when using our model line. By minimising the sum of the square of the residuals (using partial differentiation) we arrive at the following estimates:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-04.html#the-method-of-least-squares",
    "href": "Ch-04.html#the-method-of-least-squares",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "",
    "text": "TipRemember\n\n\n\n\\[\n\\hat{\\beta}_1=\\dfrac{\\sum_{i=1}^nx_iy_i-n\\bar{x}\\bar{y}}{\\sum_{i=1}^nx_i^2-n\\bar{x}^2}=\\dfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}=\\dfrac{S_{xy}}{S_{xx}};\n\\] and \\[\n\\hat{\\beta}_0=\\bar{y}-\\hat{\\beta}_1\\bar{x}.\n\\] Note that \\[\nS_{yy}=\\sum_{i=1}^n(y_i-\\bar{y})^2=\\sum_{i=1}^ny_i^2-n\\bar{y}^2.\n\\] The least squares model is therefore \\[\n\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x.\n\\tag{4.1}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-04.html#correlation",
    "href": "Ch-04.html#correlation",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "Correlation",
    "text": "Correlation\nThe strength of a linear relationship between the variables can be measured by the Pearson correlation coefficient (or just the correlation coefficient) which is given by\n\n\n\n\n\n\nTipRemember\n\n\n\n\\[\nr=\\dfrac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}.\n\\]\n\n\n\\(r\\) can take values between \\(-1\\) and \\(1\\) where \\(-1\\) and \\(1\\) represent a perfect linear relationship. \\(r=0\\) means that there is no linear relationship. A positive value of \\(r\\) denotes a positive correlation while a negative value of \\(r\\) denotes a negative correlation. As a general rule of thumb we use the following criteria:\n\n\n\n\n\n\nTipRemember\n\n\n\n\\[\n\\begin{aligned}\n|r|&gt;0.7 & \\quad \\text{Strong correlation}\\\\\n0.7\\geq |r|&gt;0.4& \\quad \\text{Moderate correlation}\\\\\n|r|\\leq 0.4 & \\quad \\text{Weak correlation}\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-04.html#simple-linear-regression",
    "href": "Ch-04.html#simple-linear-regression",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "4.2 Simple Linear Regression",
    "text": "4.2 Simple Linear Regression\nThis is a process to obtain a suitable straight line to predict values of one variable (\\(y\\)) from the values of the other (\\(x\\)), where there is a linear relationship between them. The most common approach is to use the least squares model above, i.e.  \\[\n\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x.\n\\] We can use the correlation coefficient \\(r\\) to test the strength of the linear relationship between the variables, as above, but also \\(r^2\\) (often \\(R^2\\) is used) can be used. \\(r^2\\) gives the proportion of the variance of \\(y\\) that is explained by variation in \\(x\\), and the closer this value is to 1 the stronger the relationship (clearly the closer \\(r^2\\) is to 0 the weaker the relationship). Essentially it measures how well the regression model fits the real data.\nNow we are in a position to return to the example above and form a regression line for the data.\nNote that correlation does not necessarily imply causation — variables may be related for no apparent reason.\n\nExample 4.1 This example investigates the relationship between revision time and exam marks — see the table below for data. The calculations that we need for the estimates \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) can be found in the following table using the fact that \\(\\bar{x}=11.8\\) and \\(\\bar{y}=59\\):\nThen \\[\n\\hat{\\beta}_1=\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i-\\bar{x})^2}=\\frac{837}{223.6}=3.743\n\\] and \\[\n\\hat{\\beta}_0=\\bar{y}-\\hat{\\beta}_1\\bar{x}=59-3.743\\times11.8=14.829.\n\\] Therefore the equation of the regression line is given by, \\[\n\\hat{y}=3.743x+14.829.\n\\] The Pearson correlation coefficient is given by \\[\nr=\\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}=\\frac{837}{\\sqrt{223.6}\\sqrt{4340}}=0.85,\n\\] indicating a strong positive correlation. The value of \\(r^2\\) is 0.723 indicating that \\(72.3\\%\\) of the variance of the Marks is explained by Revision. We conclude therefore that the regression model fits the data well in this case.\nThe regression line can then be used to estimate the value of \\(y\\) for a given \\(x\\), for example, if we wanted to predict the exam mark obtained for 11 hours of revision we obtain, \\[\n\\hat{y}=3.743\\times11+14.829\\approx56.\n\\] Common sense should be used when predicting using the regression model; we cannot predict outside the possible range of the \\(x\\) values, we would not, for example, try to predict what happens if a student were to revise for -5 hours.\n\n\nExample 4.2 Calculate a regression line for the data below (the relevant conditions for linear regression may be assumed):\nwhere \\[\n\\begin{aligned}\n\\bar{x}&=12.8\\\\\n\\bar{y}&=59\\\\\nS_{xx}&=\\sum_{i=1}^n(x_i-\\bar{x})^2=821.6\\\\\nS_{xy}&=\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})=-1839\\\\\nS_{yy}&=\\sum_{i=1}^n(y_i-\\bar{y})^2=4340.\n\\end{aligned}\n\\] We now find \\[\n\\begin{aligned}\n\\hat{\\beta}_1&=\\frac{S_{xy}}{S_{xx}}=\\frac{-1839}{821.6}=-2.238\\\\\n\\hat{\\beta}_0&=\\bar{y}-\\hat{\\beta}_1\\bar{x}=87.65.\\\\\n\\end{aligned}\n\\] Therefore the regression line is given by \\[\n\\hat{y}=-2.238x+87.650.\n\\] and the correlation coefficient by \\[\nr=\\frac{S_{xy}}{\\sqrt{S_{xx}S_{yy}}}=\\frac{-1839}{\\sqrt{821.6}\\sqrt{4340}}=-0.97,\n\\] indicating a very strong negative correlation. \\(r^2=0.941\\), indicating that \\(94.1\\%\\) of the variance of Marks is explained by Classes Missed and we conclude that the regression model fits the data very well.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-04.html#multiple-linear-regression",
    "href": "Ch-04.html#multiple-linear-regression",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "4.3 Multiple Linear Regression",
    "text": "4.3 Multiple Linear Regression\nThis method is an extension of the model we met in simple linear regression, i.e. \\[\ny=\\beta_0+\\beta_1x+\\epsilon\n\\] to the model\n\n\n\n\n\n\nTipRemember\n\n\n\n\\[\ny=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\cdots+\\beta_nx_n+\\epsilon,\n\\]\n\n\nwhere we have \\(n\\) independent variables, \\(x_1,\\ldots,x_n\\) and the single dependent variable \\(y\\) (dependent on these \\(x_1,\\ldots,x_n\\)).\nIn particular, we will concentrate on the case where we have 2 independent variables \\(x_1\\) and \\(x_2\\), i.e. the model, \\[\ny=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\epsilon.\n\\] Obtaining the equations for the coefficients is easier if we code the variables in the following way: \\[\n\\begin{aligned}\nv_i&=y_i-\\bar{y}, \\\\\nu_{1i}&=x_{1i}-\\bar{x}_1, \\\\\nu_{2i}&=x_{2i}-\\bar{x}_2.\n\\end{aligned}\n\\] We now write the model as \\[\nV=\\beta_0'+\\beta_1u_1+\\beta_2u_2+e.\n\\] The constant term changes from \\(\\beta_0\\) to \\(\\beta_0'\\). Again the method of least squares is used where the quantity to be minimised with respect to variation in \\(\\beta_0'\\), \\(\\beta_1\\) and \\(\\beta_2\\) is \\[\nQ=\\sum_{i=1}^n(v_i-\\beta_0'-\\beta_1u_{1i}-\\beta_2u_{2i})^2.\n\\]\nAgain, we will not go into the details of this process as it uses methods that are beyond the scope of this module. Essentially the process results with the equations: \\[\n\\begin{aligned}\n\\hat{\\beta}_1\\sum_{i=1}^n u^2_{1i}+\\hat{\\beta}_2\\sum_{i=1}^n u_{1i}u_{2i}&=\\sum_{i=1}^n u_{1i}v_i,\\\\\n\\hat{\\beta}_1\\sum_{i=1}^n u_{1i}u_{2i}+\\hat{\\beta}_2\\sum_{i=1}^n u_{2i}^2&=\\sum_{i=1}^n u_{2i}v_i.\n\\end{aligned}\n\\] These are sometimes called the normal equations — although no relation to the normal distribution. Using the notations \\[\n\\begin{aligned}\nS_{pq}=&\\sum_{i=1}^n u_{pi}u_{qi}=\\sum_{i=1}^n(x_{pi}-\\bar{x}_p)(x_{qi}-\\bar{x}_q), p,q=1,2,\\\\\nS_{0p}=&\\sum_{i=1}^n u_{pi}v_i=\\sum_{i=1}^n(x_{pi}-\\bar{x}_p)(y_i-\\bar{y}), p=1,2,\n\\end{aligned}\n\\] we may write the normal equations as \\[\n\\begin{aligned}\n\\hat{\\beta}_1S_{11}+\\hat{\\beta}_2S_{12}&=S_{01},\\\\\n\\hat{\\beta}_1S_{12}+\\hat{\\beta}_2S_{22}&=S_{02}.\n\\end{aligned}\n\\] Using standard techniques for solving simultaneous equations and \\(D=S_{11}S_{22}-S^2_{12}\\) we find \\[\n\\begin{aligned}\n\\hat{\\beta}_1&=\\frac{S_{22}S_{01}-S_{12}S_{02}}{D}\\\\\n\\hat{\\beta}_2&=\\frac{S_{11}S_{02}-S_{12}S_{01}}{D}.\n\\end{aligned}\n\\] Finally, \\[\n\\hat{\\beta}_0=\\bar{y}-b_1\\bar{x}_1-b_2\\bar{x}_2.\n\\] this gives us the following model: \\[\n\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\hat{\\beta}_2x_2.\n\\]\nIf we return to the example of predicting exam marks, but now based on both Revision Hours and Coursework Marks, this would be a situation of a multiple linear regression with two predictor/independent variables.\n\nExample 4.3 Dice were thrown to obtain ten values of each of the following: \\(X_1=\\) value on a twelve-sided die, \\(X_2=\\) twice the value on a six-sided die, \\(Z=\\)value on a six-sided die, \\(Y=X_1+X_2+Z\\). The values obtained were\nWe find that \\[\n\\begin{aligned}\nS_{11}&=\\sum_{i=1}^n(x_{1i}-\\bar{x}_1)^2=\\sum_{i=1}^n x_{1i}^2-\\frac{(\\sum_{i=1}^n x_{1i})^2}{n}=58.1\\\\[3mm]\nS_{22}&=\\sum_{i=1}^n(x_{2i}-\\bar{x}_2)^2=\\sum_{i=1}^n x_{2i}^2-\\frac{(\\sum_{i=1}^n x_{2i})^2}{n}=120.4\\\\[3mm]\nS_{12}&=\\sum_{i=1}^n(x_{1i}-\\bar{x}_1)(x_{2i}-\\bar{x}_2)=\\sum_{i=1}^n x_{1i}x_{2i}-\\frac{\\sum_{i=1}^n x_{1i}\\sum_{i=1}^n x_{2i}}{n}=-16.2\\\\[3mm]\nS_{01}&=\\sum_{i=1}^n(x_{1i}-\\bar{x}_1)(y_i-\\bar{y})=\\sum_{i=1}^n x_{1i}y_i-\\frac{\\sum_{i=1}^n x_{1i}\\sum_{i=1}^n y_i}{n}=45.6\\\\[3mm]\nS_{02}&=\\sum_{i=1}^n(x_{2i}-\\bar{x}_2)(y_i-\\bar{y})=\\sum_{i=1}^n x_{2i}y_i-\\frac{\\sum_{i=1}^n x_{2i} \\sum_{i=1}^n y_i}{n}=84.8.\n\\end{aligned}\n\\] This gives the normal equations as follows: \\[\n\\begin{aligned}\n58.1\\hat{\\beta}_1-16.2 \\hat{\\beta}_2&=45.6\\\\\n-16.2\\hat{\\beta}_1+120.4\\hat{\\beta}_2&=84.8.\n\\end{aligned}\n\\] Then \\[\n\\begin{aligned}\nD&=58.1\\times120.4-(16.2)^2=6732.8\\\\[3mm]\n\\hat{\\beta}_1&=\\frac{120.4\\times45.6+16.2\\times84.8}{D}=1.019\\\\[3mm]\n\\hat{\\beta}_2&=\\frac{58.1\\times84.8+16.2\\times45.6}{D}=0.841\\\\[3mm]\n\\hat{\\beta}_0&=18.2-1.019\\times7.7-0.841\\times6.6=4.803.\n\\end{aligned}\n\\] Therefore the regression equation is \\[\n\\hat{y}=4.803+1.019x_1+0.841x_2.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-04.html#binary-logistic-regression",
    "href": "Ch-04.html#binary-logistic-regression",
    "title": "4  Linear Regression and Correlation, Logistic Regression",
    "section": "4.4 (Binary) Logistic Regression",
    "text": "4.4 (Binary) Logistic Regression\nThe main use of logistic regression is to predict a binary outcome from a linear combination of independent variables. For example, we may wish to predict the probability of passing an exam from the independent variables attendance at lectures and hours of revision. This is also used in insurance to calculate the propensity to claim.\nFirstly, the dependent variable \\(Y\\sim Bin(1,p)\\), and we want to use the a linear combination of the independent variables to predict \\(p\\).\nFor this method we make use of the logit function, which is the log odds. In particular, we have\n\\[      \nodds=\\frac{p}{1-p}.      \n\\]\nThen, the link function we use is\n\\[   \n\\text{logit}(p)=\\ln(odds)=\\ln\\left(\\frac{p}{1-p}\\right).      \n\\]\nThe graph of this function is as follows:\n\n\n\n\n\n\n\n\nFigure 4.3\n\n\n\n\n\nTherefore, the model we consider is the following:\n\\[\n\\text{logit}(p)=\\ln\\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1x_1+\\beta_2 x_2+\\cdots+\\beta_nx_n      \n\\tag{4.2}\\]\nfor independent, or predictor variables \\(x_1,\\ldots, x_n\\) and constant coefficients \\(\\beta_0,\\ldots,\\beta_n\\).\nAs we will be seeking estimates of \\(p\\), i.e. \\(\\hat{p}\\), from independent variables that could take any real value, it makes sense to next consider the inverse of the logit function. Let \\[\ny=\\beta_0+\\beta_1x_1+\\cdots+\\beta_nx_n,\n\\] then\n\\[\n\\begin{aligned}       \n&e^y=\\frac{p}{1-p}\\\\      \n\\implies & p=(1-p)e^y=e^y-pe^y\\\\      \n\\implies & p(1+e^y)=e^y\\\\      \n\\implies & p=\\frac{e^y}{1+e^y}=\\frac{e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_nx_n}}{1+e^{\\beta_0+\\beta_1x_1+\\cdots+\\beta_nx_n}}     \n\\end{aligned}\n\\]\nThis is an example of a sigmoid function, the graph of which is as follows:\n\n\n\n\n\n\n\n\nFigure 4.4\n\n\n\n\n\nFrom the graph above, we can see that for any real input \\(y\\), we get \\(0&lt;p&lt;1\\) which intuitively makes sense.\nIn practice, we obtain an estimate \\(\\hat{p}\\) of \\(p\\) using maximum likelihood estimates of the coefficients \\(\\beta_0,\\beta_1,\\ldots,\\beta_n\\), i.e.\n\\[   \n\\hat{p}=\\frac{e^{\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\cdots+\\hat{\\beta}_nx_n}}{1+e^{\\hat{\\beta}_0+\\hat{\\beta}_1x_1+\\cdots+\\hat{\\beta}_nx_n}}.      \n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Linear Regression and Correlation, Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Ch-05.html",
    "href": "Ch-05.html",
    "title": "5  Continuous Probability Distributions",
    "section": "",
    "text": "5.1 Continuous Random Variables and their Characteristics\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nWe recall that, see Definition 3.1, a random variable \\(X\\) is a function \\(X:\\Omega\\to\\mathbb{R}\\).\nWe recall also, see Definition 3.3, that a probability distribution of a random variable \\(X:\\Omega\\to\\mathbb{R}\\) is a mapping which assigns to each interval \\(E\\subset\\mathbb{R}\\) the value of \\(\\P\\bigl(X\\in E\\bigr)\\).\nFigure 5.1: Visual representation of probabilities for a continuous random variable\nRecall that the expected value (mean) \\(\\E(X)\\) of a random variable \\(X\\) is the average value it takes.\nRecall that the variance \\(\\var(X)\\) of a random variable \\(X\\) is a measure of the spread of its values, and it is defined through the formulas \\[\n\\var(X) = \\E\\Bigl((X - \\E(X))^2\\Bigr)=\\E\\bigl(X^2\\bigr) - \\bigl(  \\E(X)\\bigr)^2\\geq0.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-05.html#continuous-random-variables-and-their-characteristics",
    "href": "Ch-05.html#continuous-random-variables-and-their-characteristics",
    "title": "5  Continuous Probability Distributions",
    "section": "",
    "text": "TipReminder\n\n\n\nIf \\(X\\) can take any values from an interval on the real line, then \\(X\\) is called a continuous random variable.\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe cumulative distribution function (CDF) of a continuous random variable \\(X:\\Omega\\to\\mathbb{R}\\) is the continuous function \\(F_X:\\mathbb{R}\\to[0,1]\\) defined by \\[\nF_X(x) =\\P(X\\leq x).\n\\] As a result, \\[\n\\P(a\\leq X\\leq b) = F_X(b)-F_X(a).\n\\]\n\n\n\nRemark. As you can see, the same formula holds for a discrete random variables, however, for continuous r.v. it does not provide an expression to calculate the probability. For this, we need the probaility denisty funciton defined below.\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe probability density function (PDF) of a continuous random variable \\(X:\\Omega\\to\\mathbb{R}\\) is the function \\(f_X:\\mathbb{R}\\to[0,\\infty)\\), such that, for any \\(a,b\\in\\mathbb{R}\\), \\[\n\\P(a\\leq X\\leq b) = \\int_a^b f_X(x)\\dx.\n\\]\nProperties:\n\n\\(f_X(x)\\geq0\\)\n\\(\\displaystyle \\int\\limits_{-\\infty}^\\infty f_X(x)\\dx =1\\)\n\\(\\displaystyle F_X(x)=\\int_{-\\infty}^x f_X(y)\\dy\\)\n\\(\\displaystyle f_X(x) = \\frac{d}{dx}F_X(x)=F_X'(x)\\)\n\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nFor conitnuous random variables, \\[\n  \\P(X=a)=0, \\qquad a\\in\\mathbb{R}.\n\\] Therefore, \\[\n\\begin{aligned}\n\\P(a\\leq X\\leq b)&=\n\\P(a\\leq X&lt; b)=\\P(a&lt; X\\leq b)\\\\\n&= \\P(a&lt; X&lt; b) = \\int_a^b f_X(x)\\dx.\n\\end{aligned}\n\\]\nAlso, the following formulas may be useful: \\[\n\\begin{aligned}\n\\P(X\\leq c) &=\\P(X&lt; c) = F_X(c)=\\int_{-\\infty}^c f_X(x)\\dx,\\\\[3mm]\n\\P(X\\geq c) & = \\P(X&gt; c) = 1- F_X(c)=\n\\int_c^{\\infty} f_X(x)\\dx.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nIf \\(X:\\Omega\\to\\mathbb{R}\\) is a continuous random variable, then \\[\n\\E(X):=\\int_{-\\infty}^\\infty x \\cdot f_X(x)\\dx\n\\] (provided that the integral takes the finite value).\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nMore generally, if \\(g: \\mathbb{R}\\to\\mathbb{R}\\), then \\[\n\\E\\bigl( g(X)\\bigr) = \\int_{-\\infty}^\\infty g(x) f_X(x) \\dx.\n\\] In particular, \\[\n\\E(X^2)= \\int_{-\\infty}^\\infty x^2 f_X(x) \\dx.\n\\]\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nIf \\(X:\\Omega\\to\\mathbb{R}\\) is a continuous random variable, then \\[\n\\begin{aligned}\n\\var{X} &= \\int_{-\\infty}^\\infty (x-\\E(X))^2 f(x)\\dx\\\\& =\\int_{-\\infty}^\\infty x^2\\cdot f_X(x)\\dx\n-\\biggl(  \\int_{-\\infty}^\\infty x\\cdot f_X(x)\\dx \\biggr)^2.\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-05.html#main-examples",
    "href": "Ch-05.html#main-examples",
    "title": "5  Continuous Probability Distributions",
    "section": "5.2 Main Examples",
    "text": "5.2 Main Examples\n\n5.2.1 Uniform distribution\n\nDefinition 5.1 The uniform distribution is a continuous probability distribution where all outcomes within a specified interval are equally likely.\n\n\n\n\n\n\n\n\n\nFigure 5.2: Graphs of PDF and CDF of \\(X\\sim U(a,b)\\).\n\n\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe PDF of the uniform distribution on an interval \\([a,b]\\) is given by \\[\n  f(x) = \\begin{cases}\n    \\dfrac{1}{b-a}, & \\text{if } a \\leq x \\leq b \\\\[3mm]\n  0, & \\text{otherwise}. \\end{cases}\n\\]\nThe CDF of the uniform distribution on an interval \\([a,b]\\) is given by \\[\n  F(x) = \\begin{cases}\n  0, & \\text{if } x&lt;a\\\\[3mm]\n    \\dfrac{x-a}{b-a}, & \\text{if } a \\leq x \\leq b \\\\[3mm]\n  1, & \\text{if } x&gt;b. \\end{cases}\n\\]\nNotation for a random variable with such distribution: \\[\nX\\sim U(a,b).\n\\]\nThe mean and variance of \\(X\\) are given by: \\[\n  \\begin{aligned}\n    \\E(X) & = \\dfrac{a+b}{2},\\\\[2mm]\n    \\var(X) & = \\dfrac{(b-a)^2}{12}.\n  \\end{aligned}\n\\]\n\n\n\nExample 5.1 Let \\(X\\sim U(1,5)\\).\n\nFind \\(\\P(2 &lt; X &lt;4)\\).\nFind \\(c\\in[1,5]\\) such that \\(\\P(3 &lt; X &lt;c) = \\dfrac13\\).\n\nSolution: a) Here \\[\nf_X(x) = \\frac{1}{5-1}=\\frac{1}{4}, \\qquad x\\in[1,5].\n\\] Therefore, \\[\n\\P(2 &lt; X &lt;4) = \\int_2^4\\frac14\\dx =\\frac14\\cdot(4-2)=\\frac12.\n\\]\n\nWe have \\[\n\\dfrac13=\\P(3 &lt; X &lt;c)=\\int_3^c \\frac14\\dx=\\frac14(c-3),\n\\] hence, \\[\nc-3=\\frac43, \\qquad  c=\\frac{13}{3}\\in[1,5].\n\\]\n\n\n\n\n5.2.2 Exponential Distribution\n\nDefinition 5.2 Recall that the (discrete) Poisson random variable models the number of independent events occurring in a fixed interval of time.The exponential distribution is a continuous probability distribution that models the time between these independent events. It is commonly used to model waiting times.\n\n\n\n\n\n\n\n\n\nFigure 5.3: Graphs of PDF and CDF of \\(X\\sim \\mathrm{Exp}(\\lambda)\\). Graphs are shown for \\(x\\geq0\\) only. Both functions are equal to \\(0\\) for \\(x&lt;0\\).\n\n\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe PDF of the exponential distribution with a parameter \\(\\lambda&gt;0\\) is defined as: \\[\nf_X(x) = \\begin{cases}\n          \\lambda e^{-\\lambda x}, & \\text{if } x \\geq 0 \\\\\n          0, & \\text{otherwise}.\n       \\end{cases}\n\\] The corresponding CDF is \\[\nF_X(x) = \\begin{cases}\n          1- e^{-\\lambda x}, & \\text{if } x \\geq 0 \\\\\n          0, & \\text{otherwise}.\n       \\end{cases}\n\\] Notation for a random variable with such distribution: \\[\nX\\sim \\mathrm{Exp}(\\lambda).\n\\] The mean and variance of \\(X\\) are given by: \\[\n  \\begin{aligned}\n    \\E(X) & = \\dfrac{1}{\\lambda},\\\\\n    \\var(X) & = \\dfrac{1}{\\lambda^2}.\n  \\end{aligned}\n\\]\n\n\n\nExample 5.2 Suppose the time between arrivals at a bus stop follows an exponential distribution with a rate parameter \\(\\lambda = 0.05\\) arrivals per minute.\n\nCalculate the probability that the next bus will arrive within the next \\(10\\) minutes.\nCalculate the probability that you would need to wait at least \\(15\\) minutes until the next bus.\nFor how long on average you would need to wait for a bus?\n\nSolution: a) Let \\(X\\sim \\mathrm{Exp}(0.05)\\) be the waiting time for the next bus. Then \\[\n\\P(X \\leq 10) = F_X(10)= 1 - e^{-0.05 \\cdot 10}=1-e^{-0.5}\\approx 0.3935.\n\\]\n\nWe need to find \\[\n\\P(X\\geq15)=1-\\P(X&lt;15)=1-F_X(10)=e^{-0.05\\cdot 15}=e^{-0.75}\\approx 0.4724.\n\\]\nSince \\[\n\\E(X)=\\frac{1}{0.05}=20,\n\\] you would need to wait, on average, for \\(20\\) minutes.\n\n\n\n\n5.2.3 Normal Distribution\n\n\n\n\n\n\nTipRemember\n\n\n\n\nThe Normal Distribution is also known as the Gaussian Distribution\nThe shape of its PDF is symmetric and often called bell-shaped.\nThe normal distribution is widely used in probability and statistics, especially, because of the central limit theorem which we will discuss later in this course. Its consequence is that the averages of large samples behave simialrly, i.e. “normally”, regardless of the individual behaviour of the elements in these samples.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5.4: Graphs of PDF of \\(X\\sim \\mathcal{N}(2,3^2)\\) and \\(X\\sim \\mathcal{N}(-2,0.5^2)\\), respectively.\n\n\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe normal distribution with the mean \\(\\mu\\in\\mathbb{R}\\) and the standard deviation \\(\\sigma&gt;0\\) is the continuous probability distribution with the PDF given by \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}.\n\\] Notation for the random variable is \\[\nX\\sim \\mathcal{N}(\\mu,\\sigma^2).\n\\] The names for the parameters \\(\\mu\\) and \\(\\sigma\\) are coming from the relations: \\[\n\\begin{aligned}\n\\E(X)&=\\mu,\\\\\n\\var(X)&=\\sigma^2.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Functions \\(\\varphi(x)\\) and \\(\\Phi(x)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Illustration that \\(\\Phi(-z)=1-\\Phi(z)\\)\n\n\n\n\n\n\n\n\nFigure 5.5: Graphs for the standard normal distribution\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe simplest case of a normal distribution is known as the standard normal distribution (or unit normal distribution), and it corresponds to \\(\\mu=0\\), \\(\\sigma=1\\). The PDF of \\(X\\sim\\mathcal{N}(0,1)\\) has special notation: \\[\n\\varphi(x):=\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}.\n\\] Therefore, if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\) then \\[\nf_X(x)= \\frac{1}{\\sigma}\\varphi\\biggl( \\frac{x-\\mu}{\\sigma} \\biggr).\n\\]\nSimilarly, for \\(X\\sim\\mathcal{N}(0,1)\\), the corresponding CDF is denoted \\[\n\\Phi(x):=\\int_{-\\infty}^x \\varphi(y)\\dy=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^x  e^{-\\frac{y^2}{2}}\\dy.\n\\] This function cannot be expressed in terms of elementary functions. To deal with it, one can use computer or statistical tables where its values are given for various values of \\(x\\) (it’s called that the function \\(\\Phi\\) is tabulated).\nIt can be shown that if \\(X\\sim \\mathcal{N}(\\mu,\\sigma^2)\\) then the corresponding CDF is \\[\nF_X(x) = \\Phi\\biggl( \\frac{x-\\mu}{\\sigma}  \\biggr).\n\\] There is a standard notation here: \\(z=\\frac{x-\\mu}{\\sigma}\\), hence, we can rewrite \\[\nF_X(x)=\\Phi(z), \\qquad z=\\frac{x-\\mu}{\\sigma}.\n\\]\nNote that \\[\n\\Phi(-z) = 1-\\Phi(z).\n\\]\n\n\nStatistical tables usually provide values of the function \\(1-\\Phi(z)\\) for \\(z\\geq0\\). It gives immediately answer for \\(\\Phi(-z)=1-\\Phi(z)\\) and for \\(\\Phi(z)=1-\\bigl(1-\\Phi(z)\\bigr)\\).\n\nFor example, from the statistical table we can find that \\[\n1-\\Phi(0.23)=0.4090.\n\\] Then \\[\n\\begin{aligned}\n\\Phi(-0.23)&=1-\\Phi(0.23)=0.4090,\\\\\n\\Phi(0.23)& =1- \\bigl( 1-\\Phi(0.23)\\bigr) = 1-0.4090=0.5910.\n\\end{aligned}\n\\]\n\nExample 5.3 Calculate the probability that a randomly selected individual has a height between \\(162\\) cm and \\(169\\) cm, given that the population mean height is \\(165\\) cm and the standard deviation is \\(10\\) cm, and that the heights follow the normal distribution.\nSolution: Let \\(X\\) be the random variable representing the height of an individual. It is given then that \\(X\\sim\\mathcal{N}(\\mu,\\sigma^2)\\), where \\(\\mu=165\\), \\(\\sigma=10\\). We need to find \\[\n\\P(162 \\leq X \\leq 173).\n\\]\nFirst step. We rewrite the required probabiligy in terms of the random variable \\[\nZ=\\frac{X-\\mu}{\\sigma}, \\qquad Z\\sim\\mathrm{N}(0,1).\n\\] Namely, we have \\[\n\\begin{aligned}\n\\P(162 \\leq X \\leq 169)&=\\P(162 -165\\leq X-165 \\leq 169-165)\\\\&\n=\\P(-3\\leq X-165 \\leq 4)\\\\&\n=\\P\\biggl(-\\frac{3}{10}\\leq \\frac{X-165}{10} \\leq \\frac{4}{10}\\biggr)\\\\&\n=\\P(-0.3\\leq Z \\leq 0.4)\\\\\n&=\\Phi(0.4)- \\Phi(-0.3).\n\\end{aligned}\n\\] From the statistical table (see above), we have that \\[\n1-\\Phi(0.4)=0.3446, \\qquad 1-\\Phi(0.3)=0.3821.\n\\] Therefore, \\[\n\\Phi(0.4)=1-0.3446=0.6554, \\qquad\n\\Phi(-0.3)=1-\\Phi(0.3)=0.3821,\n\\] and hence, \\[\n\\P(162 \\leq X \\leq 169)= 0.6554-0.3821=0.2733.\n\\]\n\nSurely, we can also use Python:\n\nfrom scipy.stats import norm\nnorm.cdf(0.4) - norm.cdf(-0.3)\n\n0.2733331637992768",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Continuous Probability Distributions</span>"
    ]
  },
  {
    "objectID": "Ch-06.html",
    "href": "Ch-06.html",
    "title": "6  Law of large numbers and the central limit theorem",
    "section": "",
    "text": "6.1 Joint behaviour of random variables\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nWe discussed with you discrete and continuous random variables. For a random variable \\(X\\), you know now how to calculate some of its characteristics: expected value \\(\\E(X)\\) and variance \\(\\var(X)\\). Now we consider how to characterise a pair of random variables.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Law of large numbers and the central limit theorem</span>"
    ]
  },
  {
    "objectID": "Ch-06.html#joint-behaviour-of-random-variables",
    "href": "Ch-06.html#joint-behaviour-of-random-variables",
    "title": "6  Law of large numbers and the central limit theorem",
    "section": "",
    "text": "ImportantMemorize\n\n\n\nLet \\(X,Y:\\Omega\\to\\R\\) be two random variables. Their joint cumulative distribution function (joint CDF) is the function \\(F_{X,Y}:\\R^2\\to\\R\\) defined by \\[\nF_{X,Y}(x,y)=\\P(X\\leq x, Y\\leq y).\n\\]\n\n\n\nRemark. In some cases, the joint CDF can be calculated manually from the description of the problem. However, in general, to calculate the joint CDF, we need to have additional information: joint probaility mass function in discrete case and joint probability density function in continuous case.\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nLet \\(X:\\Omega\\to\\{x_1,x_2,\\ldots\\}\\) and \\(Y:\\Omega\\to\\{y_1,y_2,\\ldots\\}\\) be two discrete random variable with the joint CDF \\(F_{X,Y}\\). Their joint probability mass function (joint PMF) is the function \\[\np_{X,Y}(x_i,y_j)=\\P(X=x_i,Y=y_j)\n\\] (we can also say that \\(p_{X,Y}(x,y)=0\\) for all other \\(x\\) and \\(y\\)). Then \\[\nF_{X,Y}(x,y) =\\sum_{x_i\\leq x}\\sum_{y_j\\leq y}p_{X,Y}(x_i,y_j).\n\\]\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nLet \\(X,Y:\\Omega\\to\\R\\) be two continuous random variable with the joint CDF \\(F_{X,Y}\\). Their joint probability density function (joint PDF) is the function \\(f_{X,Y}:\\R^2\\to\\R\\) such that \\[\nF_{X,Y}(x,y) = \\int_{-\\infty}^x\\biggl(\\int_{-\\infty}^y f_{X,Y}(u,v)\\,\\mathrm{d}v \\biggr) \\mathrm{d}u.\n\\] Note that \\[\n\\int_{-\\infty}^\\infty\\biggl(\\int_{-\\infty}^\\infty f_{X,Y}(u,v)\\,\\mathrm{d}v \\biggr) \\mathrm{d}u = 1.\n\\]\n\n\n\nExample 6.1 If joint PMF (for the discrete case) or joint PDF (for the continuous case) are not given explicitly, the joint CDF can be usually calculated only in very special cases, e.g. when one of variable is defined in terms of another one. For example, consider \\(X\\sim U(0,1)\\) and \\(Y=X^2\\), then \\(F_{X,Y}(x,y)=0\\) if \\(x&lt;0\\) or \\(y&lt;0\\), and for \\(x\\geq0, y\\geq0\\), we have \\[\n\\begin{aligned}\nF_{X,Y}(x,y)& = \\P(X\\leq x, X^2\\leq y)=\\P(0\\leq X\\leq x, X^2\\leq y) \\\\ &=\n  \\P(0\\leq X\\leq x, -\\sqrt{y}\\leq X\\leq \\sqrt{y})\\\\\n  &=\\P(0\\leq X\\leq \\min\\{x,\\sqrt{y}\\})\\\\\n  & = \\begin{cases}\n    1, & \\text{if } \\min\\{x,y\\}\\geq 1,\\\\\n    \\min\\{x,\\sqrt{y}\\}, & \\text{if } \\min\\{x,y\\}&lt; 1.\n  \\end{cases}\n\\end{aligned}\n\\] However, if we just have two random variables, e.g. \\(X\\sim U(0,1)\\) and \\(Y=\\sim(0,1)\\), then we can’t calculate \\(F_{X,Y}\\), unless we explicitly define the function \\(f_{X,Y}\\).\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\n\nIn the discrete case: for any \\(g:\\R^2\\to\\R\\), \\[\n\\E(g(X,Y)) = \\sum_{i}\\sum_{j}g(x_i,y_j)p_{X,Y}(x_i,y_j),\n\\] in particular, \\[\n\\E(XY) = \\sum_{i}\\sum_{j} x_i y_j p_{X,Y}(x_i,y_j).\n\\]\nIn the continuous case: for any \\(g:\\R^2\\to\\R\\), \\[\n\\E(g(X,Y)) = \\int_{-\\infty}^\\infty \\biggl(\\int_{-\\infty}^\\infty g(x,y)\\cdot f_{X,Y}(x,y)\\dy\\biggr)\\dx,\n\\] in particular, \\[\n\\E(X\\,Y) = \\int_{-\\infty}^\\infty\\biggl(\\int_{-\\infty}^\\infty x\\cdot y\\cdot f_{X,Y}(x,y)\\dy\\biggr)\\dx.\n\\]\n\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nFor the given joint PDF \\(f_{X,Y}\\) (for the continuous case), we can calculate PDFs of \\(X\\) and \\(Y\\) (so-called marginal PDFs): \\[\n\\begin{aligned}\nf_X(x) &= \\int_{-\\infty}^\\infty f_{X,Y}(x,y)\\dy,\\\\\nf_Y(y) &= \\int_{-\\infty}^\\infty f_{X,Y}(x,y)\\dx.\n\\end{aligned}\n\\] Stress that, however, for given \\(f_X\\) and \\(f_Y\\) one can’t uniquely recover \\(f_{X,Y}\\).\nSimilarly, for the discrete case, we can define the marginal PMFs, e.g. \\[\n\\begin{aligned}\np_X(x_i) = \\sum_{j}p_{X,Y}(x_i,y_j),\\\\\np_Y(y_j) = \\sum_{i}p_{X,Y}(x_i,y_j).\n\\end{aligned}\n\\] Again, one can’t uniquely recover \\(p_{X,Y}\\) by the pair of \\(p_X\\) and \\(p_Y\\).\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nRecall that two random variables \\(X\\) and \\(Y\\) are independent if, for any \\(a,b\\in\\R\\), the events \\(\\{X\\leq a\\}\\) and \\(\\{Y\\leq b\\}\\) are independent, i.e. if \\[\n\\P(X\\leq a, Y\\leq b) = \\P(X\\leq a) \\P(Y\\leq b),\n\\] i.e. for all \\(x\\) and \\(y\\), \\[\nF_{X,Y}(x,y) = F_X(x) F_Y(y).\n\\] We also have then that: in the discrete case, \\[\np_{X,Y}(x_i,y_j)=p_X(x_i)p_Y(y_j),\n\\] and, in the continuous case, \\[\nf_{X,Y}(x,y) = f_X(x) f_Y(y).\n\\]\nTherefore, in both cases, we have that, for independent random variables, \\[\n\\E(XY) = \\E(X)\\E(Y).\n\\]\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nLet \\(X:\\Omega\\to\\R\\) and \\(Y:\\Omega\\to\\R\\) be two random variables (discrete or continuous). Covariance \\(\\cov(X,Y)\\) describes the joint variability of these random variables, and it is defined by \\[\n\\begin{aligned}\n\\cov(X,Y) :&= \\E\\Bigl(\\bigl(X-\\E(X)\\bigr) \\cdot \\bigl(Y-\\E(Y)\\bigr)\\Bigr) \\\\&\n= \\E(XY) - \\E(X)\\E(Y).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nFor any \\(X,Y,V,W:\\Omega\\to\\R\\), \\(a,b,c,d\\in\\R\\),\n\n\\(\\cov(X,Y)=\\cov(Y,X)\\)\n\\(\\cov(X,X)=\\var(X)=\\sigma^2(X)\\)\n\\(\\cov(X,a)=0\\)\n\\(\\cov(aX, bY)=ab\\cov(X,Y)\\)\n\\(\\cov(X+a,Y+b)=\\cov(X,Y)\\)\n\\(\\cov(aX+bY,cV+dW)=ac\\cov(X,V)\\) \\({}\\quad + ad\\cov(X,W)+bc\\cov(Y,V)+bd\\cov(Y,W)\\)\n\\(\\var(aX+bY)=a^2\\var(X)+b^2\\var(Y) +2ab\\cov(X,Y)\\)\n\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nFor any random variables \\(X,Y:\\Omega\\to\\R\\), we define their correlation as follows \\[\n\\corr(X,Y)=\\dfrac{\\cov(X,Y)}{\\sigma(X)\\cdot\\sigma(Y)}.\n\\] It can be proved that \\[\n\\bigl\\lvert \\corr(X,Y)\\bigr\\rvert \\leq 1,\n\\] i.e.  \\[\n-1\\leq \\corr(X,Y)\\leq 1.\n\\]\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nTwo random variables, \\(X\\) and \\(Y\\), are called uncorrelated if their covariance is zero: \\(\\cov(X,Y)=0\\) (and, hence, their correlation is also zero: \\(\\corr(X,Y)=0\\)).\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nFor uncorrelated random variables \\(X\\) and \\(Y\\) and for any \\(a,b\\in\\R\\), \\[\n\\var(a X + b Y) = a^2\\var(X)+b^2\\var(Y).\n\\]\n\n\n\n\n\n\n\n\nTipReminder\n\n\n\nRecall, that for independent random variables \\(X\\) and \\(Y\\), \\(\\E(XY)=\\E(X)\\E(Y)\\), and hence \\(\\cov(X,Y)=0\\). Therefore, independent random variables are uncorrelated. The opposite statement is wrong that is shown by the following example.\n\n\n\nExample 6.2 Let \\(X\\sim U(-1,1)\\) and \\(Y=X^2\\). Then \\(XY=X^3\\), and hence \\[\n\\cov(X,Y)=\\E(XY)-\\E(X)\\E(Y)=\\E(X^3)-\\E(X)\\E(X^2).\n\\] We know that \\[\n\\E(X)= \\frac{(-1)+1}{2}=0.\n\\] Next, since \\(f_X(x)=\\frac12\\) for \\(x\\in(-1,1)\\) and \\(f_X(x)=0\\) otherwise, we have \\[\n\\begin{aligned}\n\\E(X^3)&=\\int_{-\\infty}^\\infty x^3 f_X(x)\\dx\n& = \\frac12\\int_{-1}^1 x^3dx=\\frac12\\biggl\\lfloor\n\\frac{x^4}{4}\\biggr\\rfloor_{-1}^1 = 0.\n\\end{aligned}\n\\] Therefore, \\(\\cov(X,Y)=0\\) i.e. \\(X\\) and \\(Y\\) are uncorrelated. However, clearly, \\(X\\) and \\(Y=X^2\\) are not independent.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Law of large numbers and the central limit theorem</span>"
    ]
  },
  {
    "objectID": "Ch-06.html#law-of-large-numbers-lln",
    "href": "Ch-06.html#law-of-large-numbers-lln",
    "title": "6  Law of large numbers and the central limit theorem",
    "section": "6.2 Law of large numbers (LLN)",
    "text": "6.2 Law of large numbers (LLN)\n\n\n\n\n\n\nTipRemember\n\n\n\nLet \\(X_1, \\ldots, X_n:\\Omega\\to\\R\\) be random variables. They are called independent if, for any \\(a_1,\\ldots,a_n\\in\\R\\) the events \\(\\{X_1\\leq a_1\\}\\), , \\(\\{X_n\\leq a_n\\}\\) are independent. Or, equivalently, if their joint CDF \\[\nF_{X_1,\\ldots,X_n}(x_1,\\ldots,x_n):=\\P(X_1\\leq x_1, \\ldots, X_n\\leq x_n)\n\\] is the product of the CDFs for each \\(X_i\\): \\[\nF_{X_1,\\ldots,X_n}(x_1,\\ldots,x_n) = F_{X_1}(x_1)\\ldots F_{X_n}(x_n).\n\\]\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nRandom variable \\(X_1, X_2, \\ldots, X_n, \\ldots\\) are called independent and identically distributed random variables (in brief, i.i.d. r.v.) if any finite group of them \\(X_1,\\ldots,X_n\\) are independent and they all have the same distribution: \\(F_{X_1}=F_{X_2}=\\ldots=F_{X_n}=\\ldots =F_X\\), where \\(X\\) is their joint distribution; i.e. \\(X_1\\sim X\\), \\(X_2\\sim X\\), .\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nLet \\(X_1, X_2,\\ldots,X_n,\\ldots\\) be i.i.d. r.v. with \\(\\E(X)=\\mu\\) and \\(\\var(X)=\\sigma^2&lt;\\infty\\). Consider the sample average \\[\n\\bar{X}_n = \\frac{X_1+\\ldots+X_n}{n}.\n\\] Then \\[\n\\E(\\bar{X}_n) = \\mu,\\qquad\\var(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\n\n\n\n\n\n\n\n\nImportantLaw of Large Numbers (LLN)\n\n\n\nLet \\(X_1, X_2,\\ldots,X_n,\\ldots\\) be i.i.d. r.v. with \\(\\E(X)=\\mu\\) and \\(\\var(X)=\\sigma^2&lt;\\infty\\). Then \\(\\bar{X}_n\\to \\mu\\) stochastically (or, it is also called in probability): namely, for each \\(\\varepsilon&gt;0\\), \\[\n\\lim_{n\\to\\infty} \\P(|\\bar{X}_n-\\mu|&gt;\\varepsilon) = 0.\n\\]\n\n\n\nRemark. In other words, the bigger \\(n\\) you take, the smaller chances are for the event \\(\\{|\\bar{X}_n-\\mu|&gt;\\varepsilon\\}\\). Equivalently, one can state that \\[\n\\lim_{n\\to\\infty} \\P(|\\bar{X}_n-\\mu|\\leq \\varepsilon) = 1,\n\\] i.e. the bigger \\(n\\) you take, the larger chances are for the event \\(|\\bar{X}_n-\\mu|\\leq \\varepsilon\\) that is equivalent to \\(\\mu-\\varepsilon&lt;\\bar{X}_n&lt;\\mu+\\varepsilon\\). Thus, informally speaking, with \\(n\\) growing, there are good chances to find \\(\\bar{X}_n\\) around \\(\\mu\\). We can choose \\(\\varepsilon\\) arbitrary small, i.e. we can require that \\(\\bar{X}_n\\) must very close to \\(\\mu\\), and the law of large numbers states that there is high probability (close to \\(1\\)) to achieve this if we take \\(n\\) alrge enough.\n\n\n\n\n\n\n\nTipRemember\n\n\n\nLet \\(A\\) be a random event as a result of an experiment; let \\(\\P(A) =p\\). Consider the Bernoulli random variable \\(X\\) with \\(X=1\\) if \\(A\\) holds and \\(X=0\\) otherwise. Let \\(X_1,\\ldots,X_n,\\ldots\\) be i.i.d. r.v. with \\(X_n\\sim X\\). Then \\[\n\\mu=\\E(X) = 1\\cdot p +0\\cdot (1-p)=p.\n\\] Next, the sample average \\(\\bar{X}_n=\\frac1n(X_1+\\ldots+X_n)\\) is the number of times when \\(A\\) took place when we repeated the experiment \\(n\\) times. (Note that \\(X_1+\\ldots+X_n\\sim Bin(n,p)\\).) Therefore, \\(\\bar{X}_n\\) is the frequency of the event \\(A\\) took place among \\(n\\) trials. Then LLN states that \\[\n\\frac{\\text{number of trials when $A$ happened}}{\\text{number $n$ of all trial}}\\to \\P(A)\n\\] in a proper sense (as \\(n\\to\\infty\\)). This corresponds to our “intuitive” understanding of the probability.\n\n\n\nExample 6.3 Consider many rolls of a fair \\(6\\)-sides dice. Let \\(X_j\\) be the score of the \\(j\\)-th roll, and \\(S_n=X_1+\\ldots+X_n\\) be the sum of the scores in the first \\(n\\) rolls. All \\(X_j\\) are i.i.d. r.v. with \\[\n\\E(X)=1\\cdot \\frac16 + 2\\cdot \\frac16 + \\ldots + 6\\cdot \\frac16=\\frac{7\\cdot 6}{2}\\cdot \\frac16 = \\frac72.\n\\] Therefore, by LLN, for any small \\(\\eps&gt;0\\), \\[\n\\lim_{n\\to\\infty}\\P\\Biggl( \\biggl\\lvert \\frac{S_n}{n} - \\frac72\\biggr\\rvert \\leq \\eps \\Biggr) = 1,\n\\] or equivalently, \\[\n\\lim_{n\\to\\infty}\\P\\biggl( \\Bigl(\\frac72-\\eps\\Bigr)n  \\leq S_n\\leq \\Bigl(\\frac72+ \\eps \\Bigr)n \\biggr) = 1.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Law of large numbers and the central limit theorem</span>"
    ]
  },
  {
    "objectID": "Ch-06.html#central-limit-theorem-clt",
    "href": "Ch-06.html#central-limit-theorem-clt",
    "title": "6  Law of large numbers and the central limit theorem",
    "section": "6.3 Central limit theorem (CLT)",
    "text": "6.3 Central limit theorem (CLT)\nAs we could see, LLN states that, for i.i.d. r.v. \\(X_n\\sim X\\), \\(n\\geq1\\), \\[\n\\overline{X}_n=\\frac{X_1+\\ldots+X_n}{n}\\to \\E(X)\n\\] stochastically (in probability) as \\(n\\to\\infty\\). We have also shown that \\(\\E(\\overline{X}_n)=\\E(X)\\) for each \\(n\\), i.e. we can reformulate LLN as follows: \\[\n\\overline{X}_n - \\E(\\overline{X}_n)\\to 0, \\qquad n\\to\\infty.\n\\]\n\n\n\n\n\n\nTipPreparation\n\n\n\nThe Central Limit Theorem (CLT) shows how fast \\(\\overline{X}_n\\) converges to \\(\\E(X)\\). To formulate it, we recall that \\(\\var(\\overline{X}_n )=\\frac{\\sigma^2(X)}{n}\\). Hence, \\[\n\\sigma(\\overline{X}_n ) = \\frac{\\sigma(X)}{\\sqrt{n}}.\n\\] We define, for \\(\\mu:=\\E(X)\\), \\(\\sigma:=\\sigma(X)\\), \\[\nZ_n:= \\frac{\\overline{X}_n - \\E(\\overline{X}_n)}{\\sigma(\\overline{X}_n )} = \\frac{\\overline{X}_n - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}=\\frac{\\sqrt{n}}{\\sigma}(\\overline{X}_n-\\mu).\n\\] Note that \\[\n\\E(Z_n) =0, \\qquad \\var(Z_n) = 1.\n\\]\n\n\n\n\n\n\n\n\nImportantCentral Limit Theorem (CLT)\n\n\n\nLet \\(X_1,\\ldots,X_n,\\ldots\\) be i.i.d. r.v. with \\(X_n\\sim X\\), \\(\\mu:=\\E(X)\\), \\(\\sigma^2:=\\var{X}&lt;\\infty\\). Let \\(Z_n\\) be defined as above. Then \\[\nZ_n\\to Z\\sim \\mathcal{N}(0,1), \\quad n\\to\\infty,\n\\] where the convergence is in distribution; the latter means that \\[\n\\lim_{n\\to\\infty}\\P(Z_n\\leq z)= \\Phi(z), \\quad z\\in\\R,\n\\] where \\(\\Phi(z)=F_Z(z)=\\P(Z\\leq z)\\). As a corollary, \\[\n\\lim_{n\\to\\infty}\\P(a\\leq Z_n\\leq b)= \\Phi(b)-\\Phi(a), \\quad a,b\\in\\R,\n\\] and \\[\n\\lim_{n\\to\\infty}\\P(Z_n\\geq c)= 1-\\Phi(c), \\quad c\\in\\R.\n\\]\n\n\n\nRemark. The central limit theorem shows, in particular, that \\(\\overline{X}_n\\) fluctuates around its expected value \\(\\E(\\overline{X}_n)=\\mu\\) with the standard deviation \\(\\sigma(\\overline{X}_n)=\\frac{\\sigma}{\\sqrt{n}}\\) which is significantly less than the standard deviation \\(\\sigma\\) for each of \\(X_n\\) around their expected value \\(\\E(X_n)=\\mu\\). And this is tru regardless of the distribution of \\(X_n\\). Consider this in an example.\n\n\nExample 6.4 The average teacher’s salary in New Jersey in 2023 is $63178. Suppose that the salaries are distributed normallly with standard deviation $7500. Hence, we have that \\(X\\sim \\mathcal{N}(63178,7500^2)\\).\nLets first find the probability that a randomly selected teacher makes less than $60000 per year. We have\n\\[\n\\begin{aligned}\n\\P(X&lt;60000)&=\\P\\biggl(\\frac{X-63178}{7500}&lt;\\frac{60000-63178}{7500}\\biggr)\\\\\n&=\\P(Z&lt;-0.42)=\\Phi(-0.42),\n\\end{aligned}\n\\] where \\(Z=\\frac{X-63178}{7500}\\sim \\mathcal{N}(0,1)\\).\nUsing statistical tables (and the equality \\(\\Phi(-0.42)=1-\\Phi(0.42)\\)) or Python commands\n\nfrom scipy.stats import norm\nnorm.cdf(-0.42)\n\n0.3372427268482495\n\n\nwe conclude that \\[\n\\P(X&lt;60000)\\approx 0.337,\n\\] i.e. one out of three randomly picked teachers may have the salary less than $60000.\nConsider now a sample of \\(100\\) teacher salaries. The sample mean (the average salary) is then \\[\n\\overline{X}_{100}=\\frac{X_1+\\ldots+X_{100}}{100}\n\\] where all \\(X_j\\sim X\\) are i.i.d. r.v. We know that \\[\n\\E(\\overline{X}_{100}) = \\E(X)=63178\n\\] and \\[\n\\sigma(\\overline{X}_{100})=\\frac{\\sigma(X)}{\\sqrt{100}}=750.\n\\] Therefore, the probability that the average salary of any sample of \\(100\\) teachers is less than $60000 per year is \\[\n\\begin{aligned}\n\\P(\\overline{X}_{100}&lt;60000)&= \\P\\biggl(\n  \\frac{\\overline{X}_{100}-63178}{750}\n  &lt;\n  \\frac{60000-63178}{750}\n  \\biggr) \\\\\n  &= \\P(\\overline{Z}_{100}&lt;-4.2)\\approx\\Phi(-4.2)\n\\end{aligned}\n\\] where the latter approximate equality is accroding to CLT. Since\n\nnorm.cdf(-4.2)\n\n1.3345749015906314e-05\n\n\nwe have that \\[\n\\P(\\overline{X}_{100}&lt;60000)\\approx 0.0000133,\n\\] i.e., informally speaking, this is very unlikely.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Law of large numbers and the central limit theorem</span>"
    ]
  },
  {
    "objectID": "Ch-07.html",
    "href": "Ch-07.html",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "",
    "text": "7.1 The Mean of \\(n\\) Observations from \\(N(\\mu, \\sigma^2)\\) (\\(\\sigma^2\\) Known)\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nThis chapter follows chapter 17 of by G.M.Clarke and D.Cooke. Another useful resource is by S.Lakin.\nIn many situations of uncertainty we have to make a choice between two possible alternatives, for example, given a coin we might ask whether it is fair. In this section we deal with the problem of finding a method for choosing between two possible outcomes.\nFor example, if \\(p\\) denotes the probability that a coin lands heads when flipped the hypotheses could be\nWhen we are faced with two hypotheses we call one of them the null hypothesis and denote it by \\(H_0\\) and the other the alternative hypothesis and denote it by \\(H_1\\). Therefore in our previous example, the null hypothesis would be \\(H_0:p=\\frac12\\) and the alternative hypothesis would be \\(H_1:p\\neq \\frac12\\).\nThe next natural question to ask is how we choose between \\(H_0\\) and \\(H_1\\)? We do this by obtaining a random sample from the distribution involved and then choosing a statistic, called the test statistic, whose value can be used to choose between \\(H_0\\) and \\(H_1\\).\nTherefore for the coin example we might decide not to reject \\[\nH_0:p=\\frac12\n\\] if after 10 flips of the coin the test statistic (no. of heads in the sample) lies between 3 and 7, or to reject \\(H_0\\) if the test statistic is at most 2 or at least 8.\nWe often specify a value for \\(\\alpha\\), usually the largest value that we are prepared to tolerate and then look for a test with this value of \\(\\alpha\\). The value of \\(\\alpha\\) is then called the significance level of the test. If \\(\\alpha=0.05\\), we say that we are testing \\(H_0\\) at the “5% level of significance” and, if the test rejects \\(H_0\\), we say that the null hypothesis is rejected at the \\(5\\%\\) level.\nThere are two types of significance tests: one-tailed; and two-tailed. We use a two-tailed test when \\(H_1\\) is two sided (e.g. \\(H_1:\\mu\\neq\\mu_0\\)). We use a one-tailed test when \\(H_1\\) is one-sided (e.g. \\(H_1:\\mu&gt;\\mu_0\\) or \\(H_1:\\mu&lt;\\mu_0\\)).\nAn alternative approach to using critical regions is using \\(\\mathbf{p}\\)-values. Instead of specifying a critical region and deciding whether or not the test statistic lies within it, the probability of obtaining a value equal to, or more extreme than the test statistic is calculated. For a one-tailed test, this probability is called the \\(p\\)-value and it is then compared with the significance level probability \\(\\alpha\\). For a two-tailed test, this probability is called the \\(\\tfrac{p-\\text{value}}{2}\\) and it is then compared with the significance level probability \\(\\frac{\\alpha}{2}\\). More on this later.\nWe cannot be sure of making the correct choice between \\(H_0\\) and \\(H_1\\). We can make two types of incorrect decision. We can reject \\(H_0\\) when it is actually true and we can accept \\(H_0\\) when it is actually false.\nThe probability of a type I error is usually denoted by \\(\\alpha\\) (and type II by \\(\\beta\\)).\nThe following steps summarise how we tackle questions of this type:\nWe now deal with the different cases.\nA random sample of \\(n\\) observations will be collected and a decision will be made by looking at the whole sample.\n\\(X\\sim N(\\mu, \\sigma^2)\\) then \\(\\overline{X}\\sim N(\\mu, \\frac{\\sigma^2}{n})\\). Therefore given a null hypothesis which states that a random sample \\(x_1, \\ldots, x_n\\) has been drawn from \\(N(\\mu, \\sigma^2)\\) we calculate \\[\n\\bar{x}=\\frac1n\\sum_{i=1}^nx_i\n\\] and test whether it has come from \\(N(\\mu, \\frac{\\sigma^2}{n})\\). In this case our test statistic is \\[\nz=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n\\] and we compare with the critical values or use the \\(p\\)-value approach in the usual way.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#the-mean-of-n-observations-from-nmu-sigma2-sigma2-known",
    "href": "Ch-07.html#the-mean-of-n-observations-from-nmu-sigma2-sigma2-known",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "",
    "text": "Example 7.5 A machine produces items having a nominal mass of \\(1kg\\). The mass of a randomly selected item \\(x\\) follows the distribution \\(X\\sim N(\\mu, (0.02)^2)\\). If \\(\\mu\\neq 1\\) then the machinery should be corrected. The mean mass of a randomly sample of 25 items was found to be \\(0.989kg\\). Test the null hypothesis that \\(H_0:\\mu=1\\) at the \\(1\\%\\) significance level.\nWe have\n\n\\(H_0:\\mu=1\\)\n\\(H_1:\\mu\\neq 1\\)\n\\(\\alpha=0.01\\)\n\nSince \\(P(Z\\leq 2.58)=0.995\\) the critical region is \\(|z|&gt;2.58\\) and the test statistic is given by \\[\nz=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}=\\frac{0.989-1}{\\frac{0.02}{5}}=-2.75.\n\\]\n\n\n\n\n\n\n\n\n\nClearly \\(-2.75\\) is in the critical region, therefore we reject \\(H_0\\) at the \\(1\\%\\) significance level and conclude that the machine settings should be corrected. Using the p-value approach we find:\n\n\n\n\n\n\n\n\n\nIn particular, \\(P(Z\\geq -2.75)=0.003&lt;0.005 (\\tfrac{\\alpha}{2})\\) and therefore we reject \\(H_0\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#the-difference-between-2-means-from-normal-distributions-with-known-variances",
    "href": "Ch-07.html#the-difference-between-2-means-from-normal-distributions-with-known-variances",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "7.2 The Difference between 2 Means from Normal Distributions with Known Variances",
    "text": "7.2 The Difference between 2 Means from Normal Distributions with Known Variances\nIf two samples are taken at random from normal distributions the first of size \\(n_1\\) from \\(N(\\mu_1, \\sigma_1^2)\\) and the second of size \\(n_2\\) from \\(N(\\mu_2, \\sigma_2^2)\\) the means of the sample may be calculated and compared. If the means are \\(\\bar{x}_1\\) and \\(\\bar{x}_2\\) respectively then the difference \\((\\bar{x}_1-\\bar{x}_2)\\) has the distribution \\[\nN(\\mu_1-\\mu_2, \\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}).\n\\] The theory then follows in the same way, with the test statistic being given by \\[\n\\frac{(\\bar{x}_1-\\bar{x}_2)-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}.\n\\]\n\nExample 7.6 A sample of size 25 is taken from \\(X\\sim N(\\mu_1, 66)\\) and the mean \\(\\bar{x}\\) was found to be 116, then another sample of size 25 is taken from \\(Y\\sim N(\\mu_2, 66)\\) and \\(\\bar{y}\\) was found to be 109. Test the following at the \\(5\\%\\) significance level.\n\n\\(H_0:\\mu_1-\\mu_2=12\\)\n\\(H_1:\\mu_1-\\mu_2\\neq 12\\)\n\nSince \\(\\alpha=0.05\\) and we have a two-tailed test then the critical region is \\(|z|&gt;1.96\\). The test statistic is \\[\nz=\\frac{\\bar{x}-\\bar{y}-(\\mu_1-\\mu_2)}{\\sqrt{\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_2^2}{n_2}}}=\\frac{7-12}{\\sqrt{5.28}}=-2.17.\n\\] Since \\(-2.17&lt;-1.96\\) then \\(-2.17\\) is in the critical region and we reject the null hypothesis and conclude that the difference between the means is not 12 at the \\(5\\%\\) significance level.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#large-sample-tests",
    "href": "Ch-07.html#large-sample-tests",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "7.3 Large Sample Tests",
    "text": "7.3 Large Sample Tests\nThe central limit theorem can be used to do significance tests for non-normal distributions when the sample sizes are large enough (30 or more). When a normal approximation can be used, its mean and variance will be \\(\\mu\\) and \\(\\frac{\\sigma^2}{n}\\) respectively. In this way we can test hypotheses about the means of distributions which are not themselves normal, provided a large sample of observations is available. We will the same methods to test hypotheses as before except that the test statistic will be only approximately \\(N(0,1)\\).\n\nExample 7.7 The number of strokes a golfer takes to complete a round of golf has mean 84.1 and standard deviation 2.6. After lessons her mean is 83.1 in 36 subsequent rounds. At the \\(5\\%\\) significance level test the null hypothesis that her standard of play is unaltered against the alternative hypothesis that it has improved, i.e.\n\n\\(H_0: \\mu=84.1\\)\n\\(H_1: \\mu&lt;84.1\\) (one-tailed)\n\\(\\alpha=0.05\\) therefore the critical region is \\(z&lt;-1.645\\)\n\nWe approximate the distribution of strokes by \\(N(\\mu, \\frac{2.6^2}{36})\\) and the test statistic is given by \\[\nz=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}=\\frac{83.1-84.1}{\\frac{2.6}{6}}=-2.31.\n\\] This lies in the critical region therefore we reject the null hypothesis and conclude that her game seems to have improved.\n\n\n\n\n\n\n\n\n\nAlternatively, using the \\(p\\)-value approach we find \\(P(Z\\leq -2.31)=0.01044&lt;0.05\\) and therefore we reject the null hypothesis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportantDefinition 7.8\n\n\n\nIf \\(x_1,\\ldots,x_n\\) is a family random variables of size \\(n\\geq 2\\) from the distribution \\(X\\sim N(\\mu,\\sigma^2)\\), the random variable \\[\nT=\\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}\n\\] is said to have a \\(t\\) distribution with \\((n-1)\\) degrees of freedom.\n\n\nAs mentioned in the definition above, for the \\(t\\) distribution we require the degrees of freedom, this is \\(n\\) minus the number of samples ((\\(n-1\\)) above due to the single sample).\nThe degrees of freedom come from the number of values that are free to vary. Let us suppose we have 4 numbers (\\(a,b,c,d\\)) and we know that the mean of these is 5. This means that \\[\na+b+c+d=20 (4\\times5).\n\\] Note that once we know 3 of the numbers above, then we can calculate the fourth and therefore only 3 of them are “free”. In this case we would have \\(3=4-1=n-1\\) degrees of freedom.\nNote that as \\(n\\to\\infty\\), the \\(t\\) distribution tends to the normal distribution. The \\(t\\) distribution has heavier tails than the normal distribution meaning that it is more likely to have values that fall further away from the mean.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#t-tests",
    "href": "Ch-07.html#t-tests",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "t-tests",
    "text": "t-tests\nIn the real world we often only have a random sample of data values with limited information about the underlying probability distribution. (Note that in the cases above the variance of the distribution is known.) The next natural question to ask is whether we can still perform hypothesis tests in these scenarios? Fortunately we can and we make use of the \\(t\\) distribution. \\(t\\)-tests may be performed on continuous data, possibly within an interval, for example, exam results as a percentage. We may also use \\(t\\)-tests on data which have 7 or more ordered categories. An example of such a data set could be the outcome of questions which have answers on the following 7 point Likert scale:\n\nStrongly Agree\nAgree\nAgree Somewhat\nUndecided\nDisagree Somewhat\nDisagree\nStrongly Disagree",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#t-test-comparing-a-sample-mean",
    "href": "Ch-07.html#t-test-comparing-a-sample-mean",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "7.4 t-test: Comparing a Sample Mean",
    "text": "7.4 t-test: Comparing a Sample Mean\nSuppose that \\(X\\sim N(\\mu, \\sigma^2)\\) where \\(\\sigma^2\\) is unknown and we wish to test the null hypothesis \\(H_0:\\mu=\\mu_0\\) against some alternative hypothesis. In this case we take a sample and we estimate \\(\\sigma^2\\) by the sample variance \\(s^2\\), but the error in doing so, in particular when \\(n\\) is small, cannot be neglected and therefore we must use the test statistic \\[\nt=\\frac{\\bar{x}-\\mu_0}{\\frac{s}{\\sqrt{n}}}\n\\] which has a \\(t\\) distribution with \\(n-1\\) degrees of freedom. The rest of the theory is similar to what we have seen with the normal distribution only that we use the \\(t\\) distribution to calculate the critical region.\n\nExample 7.9 Yarn breaking strength follows a normal distribution with mean of \\(21N\\). It is claimed that if the yarn is treated with a chemical then the mean breaking strength increases. A random sample of 9 lengths are taken, the value of the sample mean and sample standard deviation are 22.75 and 2.109 respectively. Test the following:\n\n\\(H_0:\\mu=21\\)\n\\(H_1:\\mu&gt;21\\) (one-tailed)\n\\(\\alpha=0.05\\)\n\nThe critical region is obtained by the \\(t\\) distribution: \\[\nt&gt;t_{0.05, 8}\\quad \\implies \\quad t&gt;1.860.\n\\] The test statistic is given by \\[\nt=\\frac{22.75-21}{\\frac{2.109}{\\sqrt{9}}}=2.5.\n\\] This value is clearly in the critical region therefore we reject the null hypothesis and accept the claim at the \\(5\\%\\) significance level. Note that \\(p\\)-values can also be used to reject the null hypothesis or not - this will be seen in the lab class.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#paired-t-test",
    "href": "Ch-07.html#paired-t-test",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "7.5 Paired t-test",
    "text": "7.5 Paired t-test\nMany statistical applications use paired data samples to draw conclusions about the difference between two population means. Data pairs occur very naturally in “before” and “after” situations, where the same object or item is measured before and after a treatment. Such data pairs are very common in science and business. Clearly in this situation the sample sizes will be equal. Assume we have \\(n\\) pairs and let \\(X_1\\) and \\(X_2\\) be the random variables that denote the observations made on the \\(n\\) pairs (the “before” and “after”) with means \\(\\mu_1\\) and \\(\\mu_2\\) respectively. The idea is to consider the difference \\(D=X_1-X_2\\), assumed to be a normally distributed random variable, with mean \\(\\mu_1-\\mu_2\\) and the null hypothesis may be that \\(\\mu_1\\) and \\(\\mu_2\\) differ by a stated amount, say \\(\\mu_0\\) (\\(\\mu_0\\) is often 0, i.e. the means do not differ). The test statistic we use in this scenario is \\[\nt=\\frac{\\bar{D}-\\mu_0}{\\frac{s_D}{\\sqrt{n}}}\n\\] where \\(s_D\\) is the sample standard deviation of \\(D\\) and \\(t\\) has a \\(t\\) distribution with \\(n-1\\) degrees of freedom.\n\nExample 7.10 Ten joints of meat are cut in half; one half is frozen and wrapped by process A and the other is frozen and wrapped by a new process B. The halves are placed in ten freezers with halves of the same joint being put in the same freezer. The number of days to spoilage are found to be:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoint number\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\\(4\\)\n\\(5\\)\n\\(6\\)\n\\(7\\)\n\\(8\\)\n\\(9\\)\n\\(10\\)\n\n\n\n\nProcess A\n\\(63\\)\n\\(109\\)\n\\(82\\)\n\\(156\\)\n\\(161\\)\n\\(155\\)\n\\(47\\)\n\\(141\\)\n\\(92\\)\n\\(149\\)\n\n\nProcess B\n\\(129\\)\n\\(105\\)\n\\(76\\)\n\\(207\\)\n\\(253\\)\n\\(146\\)\n\\(62\\)\n\\(160\\)\n\\(90\\)\n\\(177\\)\n\n\n\nAssuming the differences between these number-pairs to be normally distributed, test:\n\n\\(H_0:\\mu_D=\\mu_B-\\mu_A=0\\)\n\\(H_0:\\mu_D=\\mu_B-\\mu_A\\neq0\\) (two-tailed)\n\\(\\alpha=0.05\\)\n\nThe sample mean and variances of the two processes are given by: \\[\n\\bar{x}_A=115.5, \\ \\ \\bar{x}_B=140.5, \\ \\ s^2_A=1800.94, \\ \\ s^2_B=3676.28.\n\\] We first need to calculate the difference of the days to spoilage \\(D\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPair number\n\\(1\\)\n\\(2\\)\n\\(3\\)\n\\(4\\)\n\\(5\\)\n\\(6\\)\n\\(7\\)\n\\(8\\)\n\\(9\\)\n\\(10\\)\nTotal\nMean\n\n\n\n\n\\(D\\)\n\\(66\\)\n\\(-4\\)\n\\(-6\\)\n\\(51\\)\n\\(92\\)\n\\(-9\\)\n\\(15\\)\n\\(19\\)\n\\(-2\\)\n\\(28\\)\n\\(250\\)\n\\(25\\)\n\n\n\\({D-\\overline{D}}\\)\n\\(41\\)\n\\(-29\\)\n\\(-31\\)\n\\(26\\)\n\\(67\\)\n\\(-34\\)\n\\(-10\\)\n\\(-6\\)\n\\(-27\\)\n\\(3\\)\n\\(0\\)\n\n\n\n\\((D-\\overline{D})^2\\)\n\\(1681\\)\n\\(841\\)\n\\(961\\)\n\\(676\\)\n\\(4489\\)\n\\(1156\\)\n\\(100\\)\n\\(36\\)\n\\(729\\)\n\\(9\\)\n\\(10678\\)\n\n\n\n\nThen \\[\ns_D^2=\\frac{1}{9}\\sum_{\\text{all pairs}}(D-\\overline{D})^2=\\frac{10678}{9}=1186.44.\n\\] The test statistic is then given by \\[\nt=\\frac{25-0}{\\sqrt{\\frac{1186.44}{10}}}=2.3.\n\\] The critical region is given by \\[\n|t|&gt;t_{0.025,9}\\quad \\implies \\quad |t|&gt;2.26.\n\\] Clearly our test statistic is in the critical region and we therefore reject \\(H_0\\) and conclude that there is evidence that there is a difference in the effectiveness of the two processes.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-07.html#unpaired-t-test",
    "href": "Ch-07.html#unpaired-t-test",
    "title": "7  Hypothesis Testing: \\(Z\\)-tests and \\(t\\)-tests",
    "section": "7.6 Unpaired t-test",
    "text": "7.6 Unpaired t-test\nIt is quite common to have data from two independent samples, for example not trying both drugs on every person in the sample, but trying one drug on some people in the sample and trying another drug on the rest. This would be an example of a situation where we might use an unpaired t-test. Assume that we have two samples chosen at random from normal distributions, the first of size \\(n_1\\) from \\(X_1\\sim N(\\mu_1,\\sigma^2)\\) and the second of size \\(n_2\\) from \\(X_2\\sim N(\\mu_2,\\sigma^2)\\). Note that both distributions have the same variance (albeit unknown) - this is important for this test. We estimate \\(\\sigma^2\\) from the samples. We consider the difference between the sample means \\(\\overline{x}_1-\\overline{x}_2\\) with the null hypothesis that \\(\\mu_1-\\mu_2=\\mu_0\\). The test statistic depends on the sample variances and this depends on whether the sample sizes are equal or not, i.e. \\(n_1=n_2\\) or \\(n_1\\neq n_2\\).\nIf \\(n_1=n_2\\) then \\(s^2=\\frac{s_1^2+s_2^2}{2}\\). If \\(n_1\\neq n_2\\) then \\[s^2=\\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{(n_1-1)+(n_2-1)}.\\] These are often called the pooled estimates of the variance \\(\\sigma^2\\). Clearly, if the sample sizes are not equal then we must give greater weight to the larger sample; the appropriate weights are the degrees of freedom corresponding to each estimate of the variance. The test statistic is given by \\[\nt=\\frac{(\\bar{x}_1-\\bar{x}_2)-(\\mu_1-\\mu_2)}{s\\sqrt{\\left(\\frac1{n_1}+\\frac1{n_2}\\right)}}\n\\] with \\(n_1+n_2-2\\) degrees of freedom. (This comes from \\((n_1-1)+(n_2-1)=n_1+n_2-2\\).)\n\nExample 7.11 A trial takes place in which eight people are given only water, whereas another group of eight people are given a new energy drink. They then have to take part in an endurance task. The results of the trial are given in the following table.\n\n\n\n\nMean\nStandard deviation\n\n\n\n\nWater (\\(x_1\\))\n\\(12.2\\)\n\\(2.4\\)\n\n\nEnergy drink (\\(x_2\\))\n\\(13.1\\)\n\\(3.1\\)\n\n\n\nNote that these samples are independent; water and energy drinks are given to two different groups of people. Assuming the relevant assumptions hold, use an unpaired t-test to decide whether people who have taken the energy drink perform better at the 5% significance level, i.e.\n\n\\(H_0:\\mu_1-\\mu_2=0\\)\n\\(H_1:\\mu_1-\\mu_2&lt;0\\) or \\(\\mu_1&lt;\\mu_2\\) (Mean of “water” less than mean of “energy drink”)\n\nSince both samples are of the same size, the pooled estimate of the standard deviation is given by \\[\ns=\\sqrt{\\frac{2.4^2+3.1^2}{2}}=2.7722,\n\\] and the test statistic is given by \\[\nt=\\frac{(12.2-13.1)-0}{{2.7722}{\\sqrt\\frac28}}=-0.6493,\n\\] with \\(n_1+n_2-2=14\\) degrees of freedom. The critical region is given by \\[\nt&lt;-t_{0.05,14}\\quad\\implies\\quad t&lt;-1.761.\n\\] Since \\(-0.6493&gt;-1.761\\) we do not reject the null hypothesis and conclude there is no evidence that the energy drink makes people perform better.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing: $Z$-tests and $t$-tests</span>"
    ]
  },
  {
    "objectID": "Ch-08.html",
    "href": "Ch-08.html",
    "title": "8  Maximum likelihood estimation",
    "section": "",
    "text": "\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\n\n\n\n\n\n\nImportantMemorize\n\n\n\nLet \\(X\\) be a discrete random variable whose distribution depends on a parameter \\(\\theta\\in\\R\\). Suppose that we observe the data \\(x_1,\\ldots,x_n\\) which is the output of this random variable \\(X\\) in course of \\(n\\) independent trials. In other words, we can say that we observe that i.i.d.r.v. \\(X_1,\\ldots, X_n\\) with \\(X_i\\sim X\\), \\(1\\leq i\\leq n\\), take certain values: \\(X_1=x_1,\\ldots, X_n=x_n\\). The likelihood, or likelihood function, is the function \\(\\mathcal{L}(\\theta)=\\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\\) of the unknown parameter \\(\\theta\\) (given the observed data \\(x_1,\\ldots,x_n\\)) which is equal to the probability to observe this data (given the value of the parameter \\(\\theta\\)): \\[\n\\begin{aligned}\n\\mathcal{L}(\\theta)&=\\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\\\\\n:&=\\P(X_1=x_1,\\ldots,X_n=x_n\\mid \\theta)\n\\\\&= \\P(X_1=x_1\\mid \\theta)\\ldots \\P(X_n=x_n\\mid \\theta).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe maximum likelihood estimator \\(\\theta_*\\) of the parameter \\(\\theta\\) is the argument of the maximum of the likelihppd function: \\[\n\\theta_*=\\mathop{\\mathrm{argmax}}_\\theta\\mathcal{L}(\\theta),\n\\] that means that \\[\n\\mathcal{L}(\\theta_*) = \\max_{\\theta}\\mathcal{L}(\\theta).\n\\]\n\n\n\n\n\n\n\n\nTipRemember\n\n\n\nThe standard approach to find \\(\\theta_*\\) is to consider the **log-likelihood* function \\[\n\\begin{aligned}\nL(\\theta):&=L(\\theta\\mid x_1,\\ldots,x_n)=\\ln \\mathcal{L}(\\theta\\mid x_1,\\ldots,x_n)\n\\\\& =  \\ln \\P(X_1=x_1\\mid \\theta)+ \\ldots + \\ln \\P(X_n=x_n\\mid \\theta).\n\\end{aligned}\n\\] Then \\(\\theta_*\\) is the point of maximum for both \\(\\mathcal{L}\\) and \\(L\\): \\[\n\\theta_*=\\mathop{\\mathrm{argmax}}_\\theta L(\\theta)=\\mathop{\\mathrm{argmax}}_\\theta\\mathcal{L}(\\theta).\n\\]\n\n\n\nRemark. The reason for this is the fact that the logarigthm \\(y=\\ln x\\) is an increasing function, and then \\[\n\\mathcal{L}(\\theta)\\leq \\mathcal{L}(\\theta_*) \\Longleftrightarrow L(\\theta)\\leq L(\\theta_*).\n\\]\n\n\n\n\n\n\n\nImportantReminder\n\n\n\nTo check that \\(\\theta_*\\) is the point of maximum of \\(L(\\theta)\\), it is enough to check that \\[\nL'(\\theta_*)=0 \\quad \\text{and} \\quad\nL''(\\theta_*)&lt;0.\n\\]\n\n\n\nExample 8.1 Let \\(X:\\Omega\\to\\{0,1\\}\\) be a Bernouilli random variable with \\(\\P(X=1)=\\theta\\) and \\(\\P(X=0)=1-\\theta\\), where \\(\\theta\\in[0,1]\\) is a parameter. Suppose that we are given a sample of the length \\(n\\) of values of \\(X\\) which contain \\(k\\) ones and \\(n-k\\) zeros (the sample has a particular order, e.g. \\(010010111001\\ldots\\)). Then the probability to get this particular sample, for any \\(\\theta\\in[0,1]\\), is \\(\\theta^k(1-\\theta)^{n-k}\\), i.e. the likelihood function for the given data is \\[\n\\mathcal{L}(\\theta) = \\theta^k(1-\\theta)^{n-k}.\n\\] Hence, the log-likehood fgunction for the given data is \\[\n\\begin{aligned}\nL(\\theta)&=\\ln \\mathcal{L}(\\theta) =\\ln\\bigl(\\theta^k(1-\\theta)^{n-k}\\bigr)\\\\\n&= \\ln \\theta^k + \\ln (1-\\theta)^{n-k}\\\\\n& =k\\ln\\theta +(n-k)\\ln(1-\\theta).\n\\end{aligned}\n\\] Then \\[\n\\begin{aligned}\nL'(\\theta)& =\\bigl( k\\ln\\theta +(n-k)\\ln(1-\\theta)\\bigr)'\\\\\n& = \\frac{k}{\\theta}-\\frac{n-k}{1-\\theta}\\\\\n& = \\frac{k(1-\\theta)-(n-k)\\theta}{\\theta(1-\\theta)}\\\\\n&= \\frac{k-n\\theta}{\\theta(1-\\theta)}.\n\\end{aligned}\n\\] Therefore, \\(L'(\\theta)=0\\) iff \\(k-n\\theta=0\\), i.e.  \\[\n\\theta=\\frac{k}{n}.\n\\] Moreover, \\[\n\\begin{aligned}\nL''(\\theta)&=(L'(\\theta))' = \\biggl( \\frac{k}{\\theta}-\\frac{n-k}{1-\\theta}\\biggr)'\n\\\\& = -\\frac{k}{\\theta^2}-\\frac{n-k}{(1-\\theta)^2}&lt;0\n\\end{aligned}\n\\] for all \\(\\theta\\in[0,1]\\), in particular, for \\(\\theta_*=\\dfrac{k}{n}\\in[0,1]\\) (as \\(0\\leq k\\leq n\\)). Therefore, \\(\\theta_*=\\dfrac{k}{n}\\) is the point of maximum of \\(L(\\theta)\\), and hence, it is the maximum likelihood estimator for the parameter \\(\\theta\\).\n\n\nRemark. Note that \\(S_n:=X_1+\\ldots+X_n\\sim Bin(n,\\theta)\\) is the binomial random variable, and \\(k\\) ones in \\(n\\) Bernoulli trials means \\(S_n=k\\). Then the sample \\(\\overline{X_n}=\\frac1{n}(X_1+\\ldots+X_n)=S_n/n\\) takes the value \\(\\frac{k}{n}\\). We have that \\[\n\\E(X) = 1\\cdot \\theta+ 0\\cdot(1-\\theta)=\\theta,\n\\] and the law of large numbers says that (in certain sense) \\[\n\\overline{X}_n\\to \\theta, \\quad n\\to\\infty.\n\\] In other words, the maximum likelihood estimator converges to the theoretical value is the size of the sample converges to infinity.\n\n\nExample 8.2 Let \\(X\\sim Po(\\lambda)\\), i.e.  \\[\n\\P(X=k)=\\frac{\\lambda^k}{k!}e^{-\\lambda}, \\quad k\\geq0.\n\\] Suppose we have a sample of \\(n\\) values of \\(X\\): \\(k_1,\\ldots,k_n\\). Then \\[\n\\begin{aligned}\n\\mathcal{L}(\\lambda)&=\\P(X=k_1\\mid\\lambda)\\ldots \\P(X=k_n\\mid\\lambda)\\\\\n& = \\frac{\\lambda^{k_1}}{k_1!}e^{-\\lambda}\\cdot\\ldots\\cdot \\frac{\\lambda^{k_n}}{k_n!}e^{-\\lambda}\\\\\n& = \\underbrace{\\frac{1}{k_1!\\ldots k_n!}}_{=: c&gt;0}\\lambda^{k_1+\\ldots+k_n}e^{-\\lambda n},\n\\end{aligned}\n\\] and therefore, \\[\n\\begin{aligned}\nL(\\lambda)&=\\ln\\mathcal{L}(\\lambda)\n\\\\& = \\ln c + (k_1+\\ldots+k_n)\\ln\\lambda-\\lambda n.\n\\end{aligned}\n\\] Then \\[\nL'(\\lambda) = \\frac{k_1+\\ldots+k_n}{\\lambda}-n,\n\\] and hence, \\(L'(\\lambda)=0\\) iff \\[\n\\lambda = \\frac{k_1+\\ldots+k_n}{n}.\n\\] Since \\[\nL''(\\lambda) = (L'(\\lambda))'=-\\frac{k_1+\\ldots+k_n}{\\lambda^2}&lt;0,\n\\] the found value \\(\\lambda_* = \\frac{k_1+\\ldots+k_n}{n}\\) is the point of maximum of \\(L\\), hence, it is the maximum likelihood estimator for the parameter \\(\\lambda\\).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Maximum likelihood estimation</span>"
    ]
  },
  {
    "objectID": "Ch-09.html",
    "href": "Ch-09.html",
    "title": "9  Time series",
    "section": "",
    "text": "9.1 Autoregressive model \\(AR(1)\\)\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nTime series is an infinite sequence of random numbers parametrized (indexed) by (discrete) time: \\[\nX_1,X_2,X_3,\\ldots, X_n, \\ldots \\in\\R.\n\\]\nIn real data, the values \\(X_1,X_2,\\ldots\\) are not independent.\nWe consider a time series \\(\\{X_n\\}\\) which satisfies \\[\nX_n=\\mu+\\alpha (X_{n-1}-\\mu)+Z_n,\n\\] whre \\(\\mu\\in\\R\\) is a constant, \\(\\{Z_n\\}\\) is a white noise, and \\(\\alpha\\in\\R\\) is a parameter. We will always assume that \\(\\{Z_n\\}\\) is independent from \\(\\{X_n\\}\\). We denote \\(Y_n=X_n-\\mu\\), then \\[\nY_n=\\alpha Y_{n-1}+Z_n.\n\\] We are going to find conditions to have \\(X_n\\) stationary. In particular, one needs that \\(\\E(X_n)\\) and \\(\\var(X_n)\\) are constants.\nSince \\(\\E(Y_n)=\\E(X_n-\\mu)=\\E(X_n)-\\mu\\) and \\(\\var(Y_n)=\\var(X_n-\\mu)=\\var(X_n)\\), we must then have both \\(\\E(Y_n)=:k\\) and \\(\\var(Y_n)=:v\\) constants. We can write \\[\n\\E(Y_n)=\\E(\\alpha Y_{n-1}+Z_n)=\\alpha \\E(Y_{n-1})+\\E(Z_n),\n\\] i.e. \\(k=\\alpha k+0\\), and hence, either \\(\\alpha=1\\) or \\(k=0\\). Next, since Z_n is independent from \\(\\{X_n\\}\\) (and hence, from \\(\\{Y_n\\}\\)), we get \\[\n\\var(Y_n)=\\var(\\alpha Y_{n-1}+Z_n)=\\alpha^2\\var(Y_{n-1})+\\var(Z_n),\n\\] i.e. \\[\nv (1-\\alpha^2)=\\sigma^2.\n\\] If \\(1-\\alpha^2=0\\), i.e. \\(\\alpha=\\pm 1\\), then \\(\\sigma=0\\), that is impossible. Hence \\(\\alpha\\neq\\pm1\\) (and thus, \\(\\E(X_n)=0\\) for all \\(n\\)). Moreover, for \\(\\alpha\\neq\\pm1\\), we have \\[\n\\var(X_n)=v=\\frac{\\sigma^2}{1-\\alpha^2}.  \n\\] Since \\(\\var(X_n)\\geq0\\), we require \\(1-\\alpha^2&gt;0\\), i.e. \\[\n|\\alpha|&lt;1 \\Longleftrightarrow -1&lt;\\alpha&lt;1.\n\\]\nFigure 9.1: Qualitative difference between stationary (blue colour) and non-stationary (red colour) time series behaviour",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-09.html#autoregressive-model-ar1",
    "href": "Ch-09.html#autoregressive-model-ar1",
    "title": "9  Time series",
    "section": "",
    "text": "ImportantMemorize\n\n\n\nIt possible to prove that, indeed, the condition \\(|\\alpha|&lt;1\\) is necessary and sufficient for the stationarity of the time series \\(\\{X_n\\}\\) given by \\(X_n=\\alpha X_{n-1}+Z_n\\). For the next classes of time series, however, it is more useful to rewrite this condition in term of the characteristic equation: for \\(AR(1)\\) \\[\nX_n=\\alpha X_{n-1}+Z_n\n\\] we consider the equation \\[\n1- \\alpha \\lambda =0.\n\\] The time series is staionary if and only if \\(|\\lambda|{\\color{red}&gt;}1\\) (note that here \\(\\lambda=\\dfrac1\\alpha\\)).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-09.html#autoregressive-model-ar2",
    "href": "Ch-09.html#autoregressive-model-ar2",
    "title": "9  Time series",
    "section": "9.2 Autoregressive model \\(AR(2)\\)",
    "text": "9.2 Autoregressive model \\(AR(2)\\)\nConsider the model \\[\nX_n=\\mu  + \\alpha_1 (X_{n-1}-\\mu)\n         + \\alpha_2 (X_{n-2}-\\mu)\n         + Z_n\n\\tag{9.1}\\]\n\n\n\n\n\n\nImportantMemorize\n\n\n\nThe characteristic equation of (9.1) is \\[\n1-\\alpha_1\\lambda -\\alpha_2\\lambda^2=0.\n\\] This equation has two roots (they are, possibly, complex numbers): \\(\\lambda_1, \\lambda_2\\). The time series (9.1) is stationary if and only if \\[\n|\\lambda_1|&gt;1 \\quad\\text{**and**}\\quad |\\lambda_2|&gt;1.\n\\]\n\n\n\n\n\n\n\n\nTipReminder\n\n\n\n\nA quadratic equation \\(ax^2+bx+c=0\\) with \\(a\\neq0\\) has two roots \\[\nx_1= \\frac{-b-\\sqrt{D}}{2a}, \\qquad\nx_2= \\frac{-b+\\sqrt{D}}{2a},\n\\] where the discriminant \\(D\\) is given by \\[\nD=b^2-4ac.\n\\] If \\(D\\leq 0\\) the roots are real numbers (and they are equal if \\(D=0\\). If \\(D&lt;0\\) the roots are complex numbers: \\(x_{1,2}= p\\pm qi\\), where \\(i^2=-1\\).\nTwo complex numbers \\(p+ qi\\) and \\(p - qi\\) has the same absolute value: \\[\n|p\\pm qi|=\\sqrt{p^2+q^2}.\n\\]\n\n\n\n\nExample 9.2 Consider the time series \\[\nX_n=\\frac1{12}X_{n-1}+\\frac12X_{n-2}+Z_n,\n\\] where \\(\\{Z_n\\}\\) is a white noise. Is \\(\\{X_n\\}\\) stationary?\nSolution: Consoder the characteristic equation \\[\n\\begin{gathered}\n1= \\frac1{12}\\lambda+\\frac12\\lambda^2,\\\\\n\\lambda^2 +\\frac16\\lambda-2=0,\\\\\nD= \\biggl( \\frac16 \\biggr)^2-4\\cdot(-2)=\\frac1{36}+8=\\frac{289}{36},\\qquad\n\\sqrt{D} = \\frac{17}{6},\\\\\n\\lambda_1=\\dfrac{-\\dfrac16-\\dfrac{17}{6}}{2}=-\\frac{18}{12}=-\\frac32,\\\\\n\\lambda_2=\\dfrac{-\\dfrac16+\\dfrac{17}{6}}{2}\n=\\frac{16}{12}=\\frac43.\n\\end{gathered}\n\\] Since \\(|\\lambda_1|=\\frac32&gt;1\\) and \\(|\\lambda_2|=\\frac43&gt;1\\), the time series \\(\\{X_n\\}\\) is stationary.\n\n\nExample 9.3 Consider the time series \\[\nX_n=\\frac1{3}X_{n-1}+\\frac23X_{n-2}+Z_n,\n\\] where \\(\\{Z_n\\}\\) is a white noise. Is \\(\\{X_n\\}\\) stationary?\nSolution: Consider the characteristic equation \\[\n\\begin{gathered}\n1= \\frac1{3}\\lambda+\\frac23\\lambda^2,\\qquad\n2\\lambda^2 +\\lambda-3=0,\\\\\nD= 1^2-4\\cdot 2\\cdot(-3)=25,\\\\\n\\lambda_1=\\dfrac{-1-5}{2\\cdot2}=-\\frac{6}{4}=-\\frac32,\\\\\n\\lambda_2=\\dfrac{-1+5}{2\\cdot2}\n=\\frac{4}{4}=1.\n\\end{gathered}\n\\] Here \\(|\\lambda_1|=\\frac32&gt;1\\), however, \\(|\\lambda_2|=1\\); hence, the time series \\(\\{X_n\\}\\) is non-stationary.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-09.html#autoregressive-model-arp",
    "href": "Ch-09.html#autoregressive-model-arp",
    "title": "9  Time series",
    "section": "9.3 Autoregressive model \\(AR(p)\\)",
    "text": "9.3 Autoregressive model \\(AR(p)\\)\nWe consider a generalisation of the previous models: \\[\nX_n=\\mu  + \\alpha_1 (X_{n-1}-\\mu)\n+\\ldots\n         + \\alpha_p (X_{n-p}-\\mu)\n         + Z_n\n\\tag{9.2}\\]\n\n\n\n\n\n\nTipRemember\n\n\n\nThe characteristic equation of (9.2) is \\[\n1-\\alpha_1\\lambda -\\ldots-\\alpha_p\\lambda^p=0.\n\\] This equation has \\(p\\) roots (if \\(\\alpha_p\\neq0\\)): \\(\\lambda_1, \\ldots, \\lambda_p\\) (possibly, complex). The time series (9.2) is stationary iff \\[\n|\\lambda_1|&gt;1, \\quad \\ldots, \\quad |\\lambda_p|&gt;1.\n\\]\n\n\n\nRemark. The roots of the characteristic equation may be found numerically, using e.g. Python.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-09.html#armapq-model",
    "href": "Ch-09.html#armapq-model",
    "title": "9  Time series",
    "section": "9.4 \\(ARMA(p,q)\\)-model",
    "text": "9.4 \\(ARMA(p,q)\\)-model\nHere “AR” stands for “autoregressive” and “MA” stands for “moving average”: this model includes past white noise, namely: \\[\n\\begin{aligned}\nX_n=\\mu  &+ \\alpha_1 (X_{n-1}-\\mu)\n+\\ldots\n         + \\alpha_p (X_{n-p}-\\mu)\n         \\\\&\\quad + Z_n\n         +\\beta_1 Z_{n-1}\n+\\ldots\n         + \\beta_q Z_{n-q}.\n\\end{aligned}\n\\]\n\n\n\n\n\n\nTipRemember\n\n\n\nThe characteristic equation and the coinditions for stationarity for \\(ARMA(p,q)\\) coincide with such for its \\(AR(p)\\) component.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "Ch-10.html",
    "href": "Ch-10.html",
    "title": "10  Data Reduction",
    "section": "",
    "text": "10.1 (Exploratory) Factor Analysis\n\\[  \n\\renewcommand{\\P}{\\mathbb{P}}  \n\\renewcommand{\\E}{\\mathbb{E}}  \n\\newcommand{\\R}{\\mathbb{R}}  \n\\newcommand{\\var}{\\mathrm{Var}}  \n\\newcommand{\\cov}{\\mathrm{cov}}  \n\\newcommand{\\corr}{\\mathrm{corr}}\n\\newcommand{\\dx}{\\,\\mathrm{d}x}\n\\newcommand{\\dy}{\\,\\mathrm{d}y}\n\\newcommand{\\eps}{\\varepsilon}\n\\]\nA useful resource for this chapter is Using Multivariate Statistics by B.G.Tabachnick and L.S.Fidell. The material taught in this chapter will be met from a machine learning perspective in MA-M17 Modelling and Machine Learning — please see chapter 4 of Essential Math for Data Science if you would like an insight into this.\nFactor Analysis (FA) and Principal Component Analysis (PCA) are statistical techniques applied to a (large) set of variables to try to reduce them into subsets of relatively independent variables. Such subsets contain variables that are correlated with one another, but largely independent of other subsets of variables and are combined into factors (or components in PCA).\nTherefore, the idea of FA and PCA is to summarise patterns of correlations among observed variables and then to use this information to reduce a large number of observed variables to a smaller number of factors. A good FA or PCA makes sense, a bad one does not, therefore a good understanding of the data is required.\nIn Factor Analysis, the subsets of variables are unobservable latent variables — we cannot measure them directly. Examples of such variables could be intelligence or social class. We could try to measure such concepts indirectly, for example by measuring occupation, salary and value of home for social class.\nMathematically, the technique involves representing the original variables as a linear combination of the “hidden” factors and an error term. If \\(Y_1,Y_2,\\ldots,Y_n\\) represent the \\(n\\) observed variables with means \\(\\mu_1,\\ldots,\\mu_n\\), and \\(F_1,\\ldots,F_m\\) represent the “hidden” \\(m\\) factors, then we may consider the centralised observations \\(X_i=Y_i-\\mu_i\\) as follows: \\[\n\\begin{aligned}\nX_1=Y_1-\\mu_1&=a_{11}F_1+a_{12}F_2+\\cdots+a_{1m}F_m+\\epsilon_1\\\\\nX_2=Y_2-\\mu_2&=a_{21}F_1+a_{22}F_2+\\cdots+a_{2m}F_m+\\epsilon_2\\\\\n\\vdots&\\hskip2cm\\vdots\\hskip2cm\\vdots\\\\\nX_n=Y_n-\\mu_n&=a_{n1}F_1+a_{n2}F_2+\\cdots+a_{nm}F_m+\\epsilon_n,\n\\end{aligned}\n\\tag{10.1}\\]\nwhere \\(a_{ij}\\) represents the factor loading of the \\(i^{\\text{th}}\\) variable on the \\(j^{\\text{th}}\\) factor and \\(\\epsilon_i\\) represents the error or unique specific factor. We assume that \\(\\epsilon_i\\) has 0 mean and specific variance \\(\\psi_i\\). In matrix notation, this can be represented as, \\[\nX=AF+\\epsilon.\n\\tag{10.2}\\]\nConsider the following illustrative example.\nThis gives a general insight into the method. We now consider the finer details of the procedure, in particular, we will investigate the methods of calculating factor loadings and determining factors. We first consider/recall the definition of the covariance of random variables, \\[\n\\begin{aligned}\n\\cov(X,Y)&=\\E((X-\\E(X))(Y-\\E(Y)))\\\\\n&=\\E(XY-\\E(X)Y-X\\E(Y)+\\E(X)\\E(Y))\\\\\n&=\\E(XY)-\\E(X)\\E(Y)-\\E(X)\\E(Y)+\\E(X)\\E(Y)\\\\\n&=\\E(XY)-\\E(X)\\E(Y).\\\\\n\\end{aligned}\n\\] For matrices, this generalises to, \\[\n\\Sigma=\\E\\left[(X-\\E(X))(X-\\E(X))^T\\right].\n\\tag{10.3}\\]\nSince the \\(X_i\\)’s are centralised in our calculations, \\(\\E(X)=0\\) in the linear model (10.2), and we obtain \\(\\Sigma\\), the covariance matrix of the variables \\(X_1,\\ldots,X_n\\), as follows: \\[\n\\Sigma=\\E(XX^T),\n\\] by (10.3) with \\(\\E(X)=0\\), and by (10.2), \\[\n\\begin{aligned}\n\\E(XX^T) &= \\E((AF+\\epsilon)(AF+\\epsilon)^T)\\\\\n&=\\E((AF+\\epsilon)(F^TA^T+\\epsilon^T))\\\\\n&=\\E(AFF^TA^T)+A\\E(F\\epsilon^T)+\\E(\\epsilon F^T)A^T+\\E(\\epsilon\\epsilon^T)\\\\\n&=AIA^T+0+0+\\Psi\\\\\n&=AA^T+\\Psi,\n\\end{aligned}\n\\] where \\(\\Psi\\) is a diagonal matrix of the specific variances \\(\\psi_i\\). We assume that the factors are uncorrelated with unit variance, hence \\(\\E(FF^T)=I\\) above. Also, the cross-multiplication terms are 0 since we assume that the factors are not correlated with the errors \\(\\epsilon\\). Note that the factors themselves have now dropped out of the calculations. Next we set, \\[\nR=AA^T=\\Sigma-\\Psi,\n\\] where \\(R\\) is known as the adjusted covariance matrix, i.e. the variance of the observations are “adjusted” by subtracting the specific variances. Like \\(\\Sigma\\), \\(R\\) is a symmetric matrix and hence using results from linear algebra we may state \\[\nR=VLV^T,\n\\] where \\(V\\) is a matrix of the eigenvectors of \\(R\\) and \\(L\\) a matrix of the eigenvalues of \\(R\\). Furthermore, \\[\n\\begin{aligned}\nR=VLV^T&=V\\sqrt{L}\\sqrt{L}V^T\\\\\n&=(V\\sqrt{L})(\\sqrt{L}V^T)\\\\\n&=(V\\sqrt{L})(V\\sqrt{L})^T\\\\\n&=AA^T,\n\\end{aligned}\n\\] where we used that \\(L\\) is diagonal, hence \\(\\sqrt{L}^T=\\sqrt{L}\\). This implies that \\[\nA=V\\sqrt{L}.\n\\tag{10.4}\\] Therefore, once the eigenvectors and eigenvalues of \\(R\\) are known, the factor loading matrix \\(A\\) is easily obtained by (10.4).\nIn Python, there are various methods of “extracting” the factors, the main one being Principle Axis Factoring which finds the least number of factors that account for the common variance of a set of variables.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Reduction</span>"
    ]
  },
  {
    "objectID": "Ch-10.html#exploratory-factor-analysis",
    "href": "Ch-10.html#exploratory-factor-analysis",
    "title": "10  Data Reduction",
    "section": "",
    "text": "Example 10.1 In an experiment, 200 primary school children were psychologically tested. The children were tested on the following (the observed variables):\n\nParagraph comprehension (\\(X_1\\));\nSentence completion (\\(X_2\\));\nWord meaning (\\(X_3\\));\nAddition (\\(X_4\\));\nCounting (\\(X_5\\)).\n\nA factor analysis gives the following linear combinations: \\[\n\\begin{aligned}\nX_1&=0.81F_1+0.06F_2+\\epsilon_1\\\\\nX_2&=0.72F_1+0.08F_2+\\epsilon_2\\\\\nX_3&=0.91F_1+0.01F_2+\\epsilon_3\\\\\nX_4&=0.02F_1+0.69F_2+\\epsilon_4\\\\\nX_5&=0.11F_1+0.92F_2+\\epsilon_5\n\\end{aligned}\n\\] Clearly, variables \\(X_1,X_2\\) and \\(X_3\\) have a high factor loading with \\(F_1\\) and a low factor loading with \\(F_2\\). Variables \\(X_4\\) and \\(X_5\\) have a low factor loading with \\(F_1\\) and a high factor loading with \\(F_2\\). This suggests that \\(F_1\\) is the factor, or latent variable, literacy skills and \\(F_2\\) is the factor, or latent variable, numeracy skills.\n\n\n\n\n\n\n\n\n\nTipRemark 10.2\n\n\n\nNote that equation (10.4) is true if all factors, or eigenvalues, are used in the model. However, we only want to consider significant factors (i.e. we may choose to ignore certain factors) and therefore we require methods of extracting and evaluating such factors.\n\n\n\n\nEvaluating Factors\nThere are various means of evaluating and extracting the factors, including:\n\nEigenvalues: one method of choosing factors is to consider factors with eigenvalues \\(&gt;1\\). This is known as the Kaiser criterion.\nScree plot: this is a plot of the eigenvalues which can indicate where there is a clear cut-off (an inflexion point) between large and small eigenvalues.\nCommunality: this is the sum of the squared loadings for a variable across factors and it provides a percentage of variance accounted for by the factors. The accepted proportions for communality are dependent on the sample size. The general rule is as follows:\n\nIf all communalities \\(&gt;0.6\\), then this is considered very strong and we may even take relatively small samples in this scenario (\\(&lt; 100\\));\nCommunalities \\(&gt;0.5\\) are adequate for sample of size \\(100-200\\), or more;\nSmaller communalities may be accepted for larger sample sizes.\n\nFactor loadings: we aim for factor loadings to be \\(\\geq0.4\\) for the main factor. We then study the observations with high loadings of a particular factor in order to try to identify the factor. Factor loadings appear in the Pattern Matrix in Python.\n\n\n\nRotations\nIn cases where the factor loading matrix \\(A\\) cannot be interpreted clearly, it may be rotated to try to improve interpretations. The aim is to maximise high correlations between factors and variables and to minimise low ones. This can be performed since the factor loading matrix is not uniquely defined. There are two different types of rotation, orthogonal and oblique.\n\n\nOrthogonal Rotations\nOrthogonal rotations are used when we assume that the factors are uncorrelated. There are various orthogonal rotations possible, with the most common being Varimax, Quartimax and Equamax. The process involves a simple matrix multiplication as follows: \\[\nA_{\\text{rotated}}=A\\Lambda,\n\\tag{10.5}\\] where \\(\\Lambda\\) is the rotation matrix, \\[\n\\begin{pmatrix}\n\\cos\\theta &-\\sin\\theta\\\\\n\\sin\\theta&\\cos\\theta\n\\end{pmatrix}.\n\\tag{10.6}\\] For the case where we have 2 factors, a typical orthogonal rotation is illustrated as follows:\n\n\n\nVarimax Rotation\nVarimax is often the most common used rotation which involves a variance maximising procedure. The goal of varimax rotation is to maximise the variance of factor loadings by making high loadings higher and low ones lower for each factor.\n\n\nQuartimax Rotation\nQuartimax does for variables what varimax does for factors. It simplifies variables by increasing the dispersion of the loadings within variables, across factors.\n\n\nEquamax Rotation\nEquamax rotation is a hybrid between varimax and quartimax that tries simultaneously to simplify the factors and the variables.\nIn conclusion, varimax rotation simplifies the factors, quartimax the variables and equamax both.\n\n\nOblique Rotation\nOblique rotations allow the factors to be correlated. In practice, this is a highly likely possibility. For example, if two of our factors were Achievement and Alcoholism, we would expect there to be a correlation between these factors. Oblique rotations also include orthogonal rotations, i.e. when the factors are assumed to be uncorrelated. For the case where we have 2 factors, a typical oblique rotation is illustrated as follows:\n\nThe two main types of oblique rotations are Direct Oblimin and Promax.\nDirect Oblimin is the default oblique rotation we will use in Python.\nThe Promax method is quicker and is therefore better to use if dealing with large data sets.\nIt is good practice to first perform an oblique rotation and to change to an orthogonal rotation if correlation between the factors does not seem to exist. In Python, this can be checked by examining the Factor Correlation Matrix \\(\\Phi\\), which is given by, \\[\n\\Phi=\\begin{pmatrix}\n\\phi_{11} & \\phi_{12} &\\cdots&\\phi_{1m}\\\\\n\\phi_{21}&\\phi_{22}&\\cdots&\\phi_{2m}\\\\\n\\vdots& & \\vdots&\\\\\n\\phi_{m1}&\\phi_{m2}&\\cdots&\\phi_{mm}\n\\end{pmatrix},\n\\] where \\(m\\) is the number of factors.\nThe general rule is to use an oblique rotation if \\(|\\phi_{ij}|&gt; 0.32\\) for all \\(i,j=1,\\ldots,m, i\\neq j\\). Clearly, we do not include the diagonal terms as these will always be 1 (i.e. the correlation of a factor with itself).\nIf an oblique rotation is found to be suitable, the elements of the Pattern Matrix are reported.\nThe following example is for illustrative purposes only.\n\nExample 10.3 In an experiment, skiers were asked about their opinions on the cost of a skiing ticket (COST), the speed of the ski lifts (LIFT), the depth of the snow (DEPTH) and the moisture of snow (POWDER). Here is the raw data,\n\n\n\nSkier\nCOST\nLIFT\nDEPTH\nPOWDER\n\n\n\n\n\\(S_1\\)\n32\n64\n65\n67\n\n\n\\(S_2\\)\n61\n37\n62\n65\n\n\n\\(S_3\\)\n59\n40\n45\n43\n\n\n\\(S_4\\)\n36\n62\n34\n35\n\n\n\\(S_5\\)\n62\n46\n43\n40\n\n\n\nWhen no limit is placed on the number of factors, we have 4 factors with eigenvalues 2.02, 1.94, 0.04 and 0.00. Using the Kaiser criterion and a scree plot, we keep the eigenvalues 2.02 and 1.94, and then we run the factor analysis again with these 2 factors only. Below is the scree plot that shows a clear distinction between the eigenvalues:\n\nOnce we run the analysis keeping only the 2 strong factors, we obtain the communalities under the extraction column in the table below:\nClearly, as these communalities are close to 1, a large proportion of the variation in each variable can be accounted for by the factors. The pattern matrix is given by,\nWe see that DEPTH and POWDER have a high factor loading with Factor 1 and that COST and LIFT have a high factor loading with Factor 2. However, since the remaining factor loadings are not negligible, we will perform rotations with the aim of obtaining a clearer interpretation. Firstly, let us consider the Direct Oblimin oblique rotation. The Factor Correlation Matrix \\(\\Phi\\) is given below,\nWe can see that \\(|\\phi_{ij}|\\leq 0.32\\) for \\(i\\neq j\\). Therefore, we conclude that an oblique rotation is not warranted and instead we use the Varimax orthogonal rotation,\nThis is a rotation in the sense of (10.6) by 0.33 radians (19 degrees). Using (10.5), we can confirm the rotated factors are given by: \\[\n\\begin{aligned}\nA_{\\text{rotated}}=A\\Lambda&=\\begin{pmatrix}\n-.40 & .90\\\\\n.25&-.95\\\\\n.93&.35\\\\\n.96&.29\n\\end{pmatrix}\\begin{pmatrix} \\cos0.33 &-\\sin0.33\\\\ \\sin0.33 &\\cos0.33     \\end{pmatrix}\\\\\n&=\\begin{pmatrix}\n-.40 & .90\\\\\n.25&-.95\\\\\n.93&.35\\\\\n.96&.29\n\\end{pmatrix}\\begin{pmatrix} .95 &-.33\\\\ .33 &.95     \\end{pmatrix}\\\\\n&=\\begin{pmatrix}\n-.08&.98\\\\-.08&-.98\\\\.99&.02\\\\1&.05\n\\end{pmatrix}\n\\end{aligned}\n\\] Here is an illustration of the rotation:\nIn this example, it is clear that the variables DEPTH and POWDER are associated with a factor concerning snow conditions. The variables COST and LIFT are associated with a factor concerning resort conditions.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Reduction</span>"
    ]
  },
  {
    "objectID": "Ch-10.html#principal-component-analysis-pca",
    "href": "Ch-10.html#principal-component-analysis-pca",
    "title": "10  Data Reduction",
    "section": "10.2 Principal Component Analysis (PCA)",
    "text": "10.2 Principal Component Analysis (PCA)\nPrincipal component analysis is similar to factor analysis in that both are used for data reduction, and they often provide similar results. However, in PCA we write the components (factors in FA) as a linear combination of the variables, where as in FA, we write the variables in terms of the factors, see (10.1). This can be expressed as follows: \\[\n\\begin{aligned}\nC_1&=e_{11}X_1+e_{12}X_2+\\cdots+e_{1n}X_n\\\\\nC_2&=e_{21}X_1+e_{22}X_2+\\cdots+e_{2n}X_n\\\\\n\\vdots&\\hskip2cm\\vdots\\\\\nC_m&=e_{m1}X_1+e_{m2}X_2+\\cdots+e_{mn}X_n,\n\\end{aligned}\n\\] where \\(C_1,\\ldots, C_m\\) represent the components, \\(X_1,\\ldots, X_n\\) are the variables and \\(e_{ij}\\) are the regression coefficients, or weights of the variables. Similar to (10.2), we can rewrite this system in matrix form as below, \\[\nC=EX.\n\\] In the case of factor analysis, the factor loadings were given by the eigenvectors and eigenvalues, however, in principal component analysis, the weightings of the variables are given by the eigenvectors and eigenvalues of the covariance matrix. The largest eigenvalue and associated eigenvector is applied to the first principal component, with the next largest applied to the second principal component etc.\n\nChoosing Principal Components\nThe principal components are chosen in the following way:\n\nThe first principal component, \\[\nC_1=e_{11}X_1+e_{12}X_2+\\cdots+e_{1n}X_n,\n\\] is chosen such that it accounts for as much variation in the data as possible, subject to the condition that \\(e_{11}^2+e_{12}^2+\\ldots e_{1n}^2=1\\).\nThe second, \\[\nC_2=e_{21}X_1+e_{22}X_2+\\cdots+e_{2n}X_n,\n\\] is chosen such that the variance is as high as possible, similarly conditional on \\(e_{21}^2+e_{22}^2+\\ldots e_{2n}^2=1\\).\nThe second principal component must be chosen such that it is uncorrelated with the first.\nThe \\(i^{\\text{th}}\\) principal component, \\[\nC_i=e_{i1}X_1+e_{i2}X_2+\\cdots+e_{in}X_n,\n\\] again is chosen such that the variance is as high as possible, conditional on \\(e_{i1}^2+e_{i2}^2+\\ldots e_{in}^2=1\\) and it being uncorrelated with all other principal components.\nAll principal components are uncorrelated with each other.\n\nAs previously stated, the weightings \\(e_{ij}\\) are obtained from eigenvectors corresponding to the \\(i^{\\text{th}}\\) largest eigenvalue.\n\n\n\n\n\n\nTipRemark 10.4\n\n\n\nThe process of maximising the variance uses the theory of Constrained Optimisation, which, in this case, essentially means maximising the variance for the \\(i^{\\text{th}}\\) principal component conditional on \\(e_{i1}^2+e_{i2}^2+\\ldots e_{in}^2=1\\).\n\n\n\n\nNumber of Components and Rotations\nWe will use the same guidelines for determining the number of components as we did for factors in factor analysis, i.e. by evaluating eigenvalues, scree plots, communalities and factor loadings. Similarly, we will use rotations in the same way for principal component analysis as we did in factor analysis, i.e. if components are not clear from the unrotated results, we next perform an oblique rotation. If there is not enough correlation between the principal components to warrant the use of an oblique rotation, we then perform an orthogonal rotation.\n\n\nDeciding between PCA and FA\nPCA is used to simply reduce the observed variables into a smaller set of important independent composite variables (components). FA tends to be used when there are suspected latent factors (not directly measurable factors) causing the observed variables.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Reduction</span>"
    ]
  }
]